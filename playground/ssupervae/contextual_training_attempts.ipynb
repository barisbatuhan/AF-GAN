{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.datasets.random_dataset import RandomDataset\n",
    "from data.datasets.golden_panels import GoldenPanelsDataset\n",
    "\n",
    "from networks.plain_ssupervae import PlainSSuperVAE\n",
    "from networks.ssupervae_contextual_attentional import SSuperVAEContextualAttentional\n",
    "from training.ssupervae_contextual_attn_trainer import SSuperVAEContextualAttentionalTrainer\n",
    "from training.vae_trainer import VAETrainer\n",
    "from utils.config_utils import read_config, Config\n",
    "from utils.plot_utils import *\n",
    "from utils.logging_utils import *\n",
    "from utils import pytorch_util as ptu\n",
    "from utils.image_utils import *\n",
    "from configs.base_config import *\n",
    "from functional.losses.elbo import elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_loss_model(model_name, model, best_loss):\n",
    "    print('[INFO] Current best loss: ' + str(best_loss))\n",
    "    torch.save(model, base_dir + 'playground/ssupervae/weights/' + model_name + \".pth\")\n",
    "\n",
    "\n",
    "def train(data_loader,\n",
    "          config,\n",
    "          panel_dim,\n",
    "          model_name='plain_ssupervae',\n",
    "          cont_epoch=-1,\n",
    "          cont_model=None):\n",
    "    # loading config\n",
    "    print(\"[INFO] Initiate training...\")\n",
    "\n",
    "    # creating model and training details\n",
    "    net = SSuperVAEContextualAttentional(config.backbone,\n",
    "                                         panel_img_size=panel_dim,\n",
    "                                         latent_dim=config.latent_dim,\n",
    "                                         embed_dim=config.embed_dim,\n",
    "                                         seq_size=config.seq_size,\n",
    "                                         decoder_channels=config.decoder_channels,\n",
    "                                         gen_img_size=config.image_dim).to(ptu.device)\n",
    "\n",
    "    criterion = elbo\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(),\n",
    "                           lr=config.lr,\n",
    "                           betas=(config.beta_1, config.beta_2),\n",
    "                           weight_decay=config.weight_decay)\n",
    "\n",
    "    d_params = list(net.local_disc.parameters()) + list(net.global_disc.parameters())\n",
    "    optimizer_disc = optim.Adam(d_params,\n",
    "                                lr=config.lr,\n",
    "                                betas=(config.beta_1, config.beta_2),\n",
    "                                weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer,\n",
    "                                            lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                            last_epoch=-1)\n",
    "\n",
    "    scheduler_disc = optim.lr_scheduler.LambdaLR(optimizer_disc,\n",
    "                                            lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                            last_epoch=-1)\n",
    "    # init trainer\n",
    "    trainer = SSuperVAEContextualAttentionalTrainer(model=net,\n",
    "                                                    config_disc=config,\n",
    "                                                    model_name=model_name,\n",
    "                                                    criterion=criterion,\n",
    "                                                    train_loader=data_loader,\n",
    "                                                    test_loader=None,\n",
    "                                                    epochs=config.train_epochs,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    optimizer_disc=optimizer_disc,\n",
    "                                                    scheduler=scheduler,\n",
    "                                                    scheduler_disc=scheduler_disc,\n",
    "                                                    grad_clip=config.g_clip,\n",
    "                                                    best_loss_action=lambda m, l: save_best_loss_model(model_name, m,\n",
    "                                                                                                       l),\n",
    "                                                    save_dir=base_dir + 'playground/ssupervae/',\n",
    "                                                    checkpoint_every_epoch=True\n",
    "                                                    )\n",
    "\n",
    "    if cont_epoch > -1:\n",
    "        epoch, losses = trainer.load_checkpoint(epoch=cont_epoch)\n",
    "    elif cont_model is not None:\n",
    "        epoch, losses = trainer.load_checkpoint(alternative_chkpt_path=cont_model)\n",
    "        print(\"[INFO] Continues from loaded model in epoch:\", epoch)\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        epoch, losses = None, {}\n",
    "\n",
    "    train_losses, test_losses = trainer.train_epochs(starting_epoch=epoch, losses=losses)\n",
    "\n",
    "    print(\"[INFO] Completed training!\")\n",
    "\n",
    "    save_training_plot(train_losses['loss'],\n",
    "                       test_losses['loss'],\n",
    "                       \"Plain_SSuperVAE Losses\",\n",
    "                       base_dir + 'playground/supervae/' + f'results/ssupervae_plot.png'\n",
    "                       )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "config = read_config(Config.VAE_CONTEXT_ATTN)\n",
    "golden_age_config = read_config(Config.GOLDEN_AGE)\n",
    "\n",
    "panel_dim = golden_age_config.panel_dim[0]\n",
    "\n",
    "cont_epoch = -1\n",
    "cont_model = None  # \"playground/ssupervae/weights/model-18.pth\"\n",
    "# TODO: move this to config\n",
    "limit_size = -1\n",
    "\n",
    "# data = RandomDataset((3, 3, 360, 360), (3, config.image_dim, config.image_dim))\n",
    "data = GoldenPanelsDataset(golden_age_config.panel_path,\n",
    "                           golden_age_config.sequence_path,\n",
    "                           golden_age_config.panel_dim,\n",
    "                           config.image_dim,\n",
    "                           augment=False,\n",
    "                           mask_val=golden_age_config.mask_val,\n",
    "                           mask_all=golden_age_config.mask_all,\n",
    "                           return_mask=golden_age_config.return_mask,\n",
    "                           train_test_ratio=golden_age_config.train_test_ratio,\n",
    "                           train_mode=True,\n",
    "                           limit_size=limit_size)\n",
    "data_loader = DataLoader(data, batch_size=config.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initiate training...\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18016 [00:00<?, ?it/s]/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Epoch 0, loss 17703.8775, reconstruction_loss 18153.0316, kl_loss 19.0924, l1_fine 1.0409, wgan_g -469.2875, wgan_d -509.7567, wgan_gp 19.8764, d -310.9925: 100%|██████████| 18016/18016 [1:57:59<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current best loss: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch 1, loss 17606.2888, reconstruction_loss 18006.1413, kl_loss 30.2759, l1_fine 1.0372, wgan_g -431.1657, wgan_d -531.1582, wgan_gp 20.4321, d -326.8370: 100%|██████████| 18016/18016 [1:57:14<00:00,  2.56it/s]\n",
      "Epoch 2, loss 17079.8024, reconstruction_loss 17378.4287, kl_loss 38.3255, l1_fine 0.9827, wgan_g -337.9343, wgan_d -493.6751, wgan_gp 18.7416, d -306.2594:  41%|████      | 7428/18016 [48:45<1:09:11,  2.55it/s]"
     ]
    }
   ],
   "source": [
    "model = train(data_loader,\n",
    "              config,\n",
    "              model_name=get_dt_string() + \"_model\",\n",
    "              cont_epoch=cont_epoch,\n",
    "              cont_model=cont_model,\n",
    "              panel_dim=panel_dim)\n",
    "torch.save(model, base_dir + 'playground/ssupervae/results/' + \"ssuper_vae_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment start time: may 14 - 18.04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
