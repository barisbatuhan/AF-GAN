{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.datasets.ffhq_dataset import FFHQDataset\n",
    "from data.datasources.ffhq_datasource import FFHQDatasource\n",
    "from data.datasources.golden_age_face_datasource import GoldenAgeFaceDatasource\n",
    "from functional.losses.bi_discriminator_loss import BidirectionalDiscriminatorLoss, BidirectionalDiscriminatorLossType\n",
    "from networks.bigan import BiGAN\n",
    "from training.bigan_trainer import BiGANTrainer\n",
    "from utils.config_utils import read_config, Config\n",
    "from utils.logging_utils import *\n",
    "from utils.plot_utils import *\n",
    "\n",
    "from data.datasets import facedataset\n",
    "from data.datasources import facedatasource\n",
    "from data.datasources.datasource_mode import DataSourceMode\n",
    "from networks.siamese_network import SiameseNetwork\n",
    "from functional.losses.contrastive_loss import ContrastiveLoss\n",
    "from functional.metrics.dissimilarity import *\n",
    "from training.face_recognition_trainer import train_epochs\n",
    "from configs.base_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save_best_loss_model(model_name, model, best_loss):\n",
    "    # print('current best loss: ' + str(best_loss))\n",
    "    logging.info('current best loss: ' + str(best_loss))\n",
    "    torch.save(model, base_dir + 'playground/bigan/results/' + model_name + \".pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image: 0\n",
      "reading image: 512\n",
      "reading image: 1024\n",
      "reading image: 1536\n",
      "reading image: 2048\n",
      "reading image: 2560\n",
      "reading image: 3072\n",
      "reading image: 3584\n",
      "reading image: 4096\n",
      "reading image: 4608\n",
      "reading image: 5120\n",
      "reading image: 5632\n",
      "reading image: 6144\n",
      "reading image: 6656\n",
      "reading image: 7168\n",
      "reading image: 7680\n",
      "reading image: 8192\n",
      "reading image: 8704\n",
      "reading image: 9216\n",
      "reading image: 9728\n",
      "reading image: 10240\n",
      "reading image: 10752\n",
      "reading image: 11264\n",
      "reading image: 11776\n",
      "reading image: 12288\n",
      "reading image: 12800\n",
      "reading image: 13312\n",
      "reading image: 13824\n",
      "reading image: 14336\n",
      "reading image: 14848\n",
      "reading image: 15360\n",
      "reading image: 15872\n",
      "reading image: 16384\n",
      "reading image: 16896\n",
      "reading image: 17408\n",
      "reading image: 17920\n",
      "reading image: 18432\n",
      "reading image: 18944\n",
      "reading image: 19456\n",
      "reading image: 19968\n",
      "reading image: 20480\n",
      "reading image: 20992\n",
      "reading image: 21504\n",
      "reading image: 22016\n",
      "reading image: 22528\n",
      "reading image: 23040\n",
      "reading image: 23552\n",
      "reading image: 24064\n",
      "reading image: 24576\n",
      "reading image: 25088\n",
      "reading image: 25600\n",
      "reading image: 26112\n",
      "reading image: 26624\n",
      "reading image: 27136\n",
      "reading image: 27648\n",
      "reading image: 28160\n",
      "reading image: 28672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-16b47c39744e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mgolden_age_config\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mConfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGOLDEN_AGE_FACE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdatasource\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGoldenAgeFaceDatasource\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgolden_age_config\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDataSourceMode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/AF-GAN/data/datasources/golden_age_face_datasource.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, config, mode)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mload_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/AF-GAN/data/datasources/golden_age_face_datasource.py\u001B[0m in \u001B[0;36mload_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mload_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mannotations_folder_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mannotations_folder_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_face_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mannot_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mannotations_folder_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread_face_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mannot_path\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/AF-GAN/data/datasources/golden_age_face_datasource.py\u001B[0m in \u001B[0;36mread_face_images\u001B[0;34m(self, annot_path)\u001B[0m\n\u001B[1;32m     45\u001B[0m                         \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m                     \u001B[0mimage_location\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpanel_folder_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mimage_location\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m                     \u001B[0mwhole_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_image_from_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mim_dim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m                     cropped_face = crop_image(whole_image,\n\u001B[1;32m     49\u001B[0m                                               \u001B[0mcrop_region\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/AF-GAN/utils/image_utils.py\u001B[0m in \u001B[0;36mread_image_from_path\u001B[0;34m(path, im_dim)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mread_image_from_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mim_dim\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'uint8'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mshape_len\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mshape_len\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/skimage/io/_io.py\u001B[0m in \u001B[0;36mimread\u001B[0;34m(fname, as_gray, plugin, **plugin_args)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mfile_or_url_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m         \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_plugin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'imread'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mplugin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mplugin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mplugin_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'ndim'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/skimage/io/manage_plugins.py\u001B[0m in \u001B[0;36mcall_plugin\u001B[0;34m(kind, *args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m                                (plugin, kind))\n\u001B[1;32m    208\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 209\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/skimage/io/_plugins/imageio_plugin.py\u001B[0m in \u001B[0;36mimread\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimageio_imread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimageio_imread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/core/functions.py\u001B[0m in \u001B[0;36mimread\u001B[0;34m(uri, format, **kwargs)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m     \u001B[0;31m# Get reader and read first\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m     \u001B[0mreader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muri\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"i\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mreader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mreader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/core/functions.py\u001B[0m in \u001B[0;36mget_reader\u001B[0;34m(uri, format, mode, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# Return its reader object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 186\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_reader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/core/format.py\u001B[0m in \u001B[0;36mget_reader\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    168\u001B[0m                 \u001B[0;34m\"Format %s cannot read in %s mode\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m             )\n\u001B[0;32m--> 170\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_writer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/core/format.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, format, request)\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_request\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0;31m# Open the reader/writer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/plugins/pillow.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, pilmode, as_gray, exifrotate)\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[0;32mclass\u001B[0m \u001B[0mReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPillowFormat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpilmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_gray\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexifrotate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 429\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mPillowFormat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpilmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpilmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_gray\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_gray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    430\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    431\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0m_get_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/plugins/pillow.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, pilmode, as_gray)\u001B[0m\n\u001B[1;32m    133\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpalette\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpalette\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirty\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpalette\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrawmode_saved\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpalette\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrawmode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 135\u001B[0;31m             \u001B[0mpil_try_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_im\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    136\u001B[0m             \u001B[0;31m# Store args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m             self._kwargs = dict(\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/imageio/plugins/pillow.py\u001B[0m in \u001B[0;36mpil_try_read\u001B[0;34m(im)\u001B[0m\n\u001B[1;32m    667\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m         \u001B[0;31m# this will raise an IOError if the file is not readable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m         \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetdata\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mIOError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0msite\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"http://pillow.readthedocs.io/en/latest/installation.html\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mgetdata\u001B[0;34m(self, band)\u001B[0m\n\u001B[1;32m   1269\u001B[0m         \"\"\"\n\u001B[1;32m   1270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1271\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1272\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mband\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1273\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetband\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mband\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/PIL/ImageFile.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m                             \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mb\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m                             \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_code\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m                                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "golden_age_config = read_config(Config.GOLDEN_AGE_FACE)\n",
    "datasource = GoldenAgeFaceDatasource(golden_age_config, mode=DataSourceMode.TRAIN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping image: 512\n",
      "skipping image: 1024\n",
      "skipping image: 1536\n",
      "skipping image: 2048\n",
      "skipping image: 2560\n",
      "skipping image: 3072\n",
      "skipping image: 3584\n",
      "skipping image: 4096\n",
      "skipping image: 4608\n",
      "skipping image: 5120\n",
      "skipping image: 5632\n",
      "skipping image: 6144\n",
      "skipping image: 6656\n",
      "skipping image: 7168\n",
      "skipping image: 7680\n",
      "skipping image: 8192\n",
      "skipping image: 8704\n",
      "skipping image: 9216\n",
      "skipping image: 9728\n",
      "skipping image: 10240\n",
      "skipping image: 10752\n",
      "skipping image: 11264\n",
      "skipping image: 11776\n",
      "skipping image: 12288\n",
      "skipping image: 12800\n",
      "skipping image: 13312\n",
      "skipping image: 13824\n",
      "skipping image: 14336\n",
      "skipping image: 14848\n",
      "skipping image: 15360\n",
      "skipping image: 15872\n",
      "skipping image: 16384\n",
      "skipping image: 16896\n",
      "skipping image: 17408\n",
      "skipping image: 17920\n",
      "skipping image: 18432\n",
      "skipping image: 18944\n",
      "skipping image: 19456\n",
      "skipping image: 19968\n",
      "skipping image: 20480\n",
      "skipping image: 20992\n",
      "skipping image: 21504\n",
      "skipping image: 22016\n",
      "skipping image: 22528\n",
      "skipping image: 23040\n",
      "skipping image: 23552\n",
      "skipping image: 24064\n",
      "skipping image: 24576\n",
      "skipping image: 25088\n",
      "skipping image: 25600\n",
      "skipping image: 26112\n",
      "skipping image: 26624\n",
      "skipping image: 27136\n",
      "skipping image: 27648\n",
      "skipping image: 28160\n",
      "skipping image: 28672\n",
      "skipping image: 29184\n",
      "skipping image: 29696\n",
      "skipping image: 30208\n",
      "skipping image: 30720\n",
      "skipping image: 31232\n",
      "skipping image: 31744\n",
      "skipping image: 32256\n",
      "skipping image: 32768\n",
      "skipping image: 33280\n",
      "skipping image: 33792\n",
      "skipping image: 34304\n",
      "skipping image: 34816\n",
      "skipping image: 35328\n",
      "skipping image: 35840\n",
      "skipping image: 36352\n",
      "skipping image: 36864\n",
      "skipping image: 37376\n",
      "skipping image: 37888\n",
      "skipping image: 38400\n",
      "skipping image: 38912\n",
      "skipping image: 39424\n",
      "skipping image: 39936\n",
      "skipping image: 40448\n",
      "skipping image: 40960\n",
      "skipping image: 41472\n",
      "skipping image: 41984\n",
      "skipping image: 42496\n",
      "skipping image: 43008\n",
      "skipping image: 43520\n",
      "skipping image: 44032\n",
      "skipping image: 44544\n",
      "skipping image: 45056\n",
      "skipping image: 45568\n",
      "skipping image: 46080\n",
      "skipping image: 46592\n",
      "skipping image: 47104\n",
      "skipping image: 47616\n",
      "skipping image: 48128\n",
      "skipping image: 48640\n",
      "skipping image: 49152\n",
      "skipping image: 49664\n",
      "skipping image: 50176\n",
      "skipping image: 50688\n",
      "skipping image: 51200\n",
      "skipping image: 51712\n",
      "skipping image: 52224\n",
      "skipping image: 52736\n",
      "skipping image: 53248\n",
      "skipping image: 53760\n",
      "skipping image: 54272\n",
      "skipping image: 54784\n",
      "skipping image: 55296\n",
      "skipping image: 55808\n",
      "skipping image: 56320\n",
      "skipping image: 56832\n",
      "skipping image: 57344\n",
      "skipping image: 57856\n",
      "skipping image: 58368\n",
      "skipping image: 58880\n",
      "skipping image: 59392\n",
      "skipping image: 59904\n",
      "skipping image: 60416\n",
      "skipping image: 60928\n",
      "skipping image: 61440\n",
      "skipping image: 61952\n",
      "skipping image: 62464\n",
      "skipping image: 62976\n",
      "skipping image: 63488\n",
      "skipping image: 64000\n",
      "skipping image: 64512\n",
      "skipping image: 65024\n",
      "skipping image: 65536\n",
      "skipping image: 66048\n",
      "skipping image: 66560\n",
      "skipping image: 67072\n",
      "skipping image: 67584\n",
      "skipping image: 68096\n",
      "skipping image: 68608\n",
      "skipping image: 69120\n",
      "skipping image: 69632\n",
      "reading image: 0\n",
      "reading image: 512\n",
      "reading image: 1024\n",
      "reading image: 1536\n",
      "reading image: 2048\n",
      "reading image: 2560\n",
      "reading image: 3072\n",
      "reading image: 3584\n",
      "reading image: 4096\n",
      "reading image: 4608\n",
      "reading image: 5120\n",
      "reading image: 5632\n",
      "reading image: 6144\n",
      "reading image: 6656\n",
      "reading image: 7168\n",
      "reading image: 7680\n",
      "reading image: 8192\n",
      "reading image: 8704\n",
      "reading image: 9216\n",
      "reading image: 9728\n",
      "reading image: 10240\n",
      "reading image: 10752\n",
      "reading image: 11264\n",
      "reading image: 11776\n",
      "reading image: 12288\n",
      "reading image: 12800\n",
      "reading image: 13312\n",
      "reading image: 13824\n",
      "reading image: 14336\n",
      "reading image: 14848\n",
      "reading image: 15360\n",
      "reading image: 15872\n",
      "reading image: 16384\n",
      "reading image: 16896\n",
      "reading image: 17408\n",
      "reading image: 17920\n",
      "reading image: 18432\n",
      "reading image: 18944\n",
      "reading image: 19456\n",
      "reading image: 19968\n",
      "reading image: 20480\n",
      "reading image: 20992\n",
      "reading image: 21504\n",
      "reading image: 22016\n",
      "reading image: 22528\n",
      "reading image: 23040\n",
      "reading image: 23552\n",
      "reading image: 24064\n",
      "reading image: 24576\n",
      "reading image: 25088\n",
      "reading image: 25600\n",
      "reading image: 26112\n",
      "reading image: 26624\n",
      "reading image: 27136\n",
      "reading image: 27648\n",
      "reading image: 28160\n",
      "reading image: 28672\n",
      "reading image: 29184\n",
      "reading image: 29696\n"
     ]
    }
   ],
   "source": [
    "annot_path = golden_age_config.annotations_folder_path\n",
    "additional_data = datasource.get_additional_data(annot_path=annot_path,\n",
    "                               from_image_count=70000,\n",
    "                               additional_image_count=30000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasource.data = np.concatenate((datasource.data, additional_data), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_config = read_config(Config.BiGAN)\n",
    "train_dataset = FFHQDataset(datasource=datasource)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_config.batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_golden_age_face_bigan(model_name='test_model'):\n",
    "    logging.info(\"initiate training\")\n",
    "    net = BiGAN(image_dim=golden_age_config.image_dim).to(ptu.device)\n",
    "    criterion = BidirectionalDiscriminatorLoss(loss_type=BidirectionalDiscriminatorLossType.VANILLA_LOG_MEAN)\n",
    "\n",
    "    d_optimizer = torch.optim.Adam(net.discriminator.parameters(),\n",
    "                                   lr=train_config.discriminator_lr,\n",
    "                                   betas=(train_config.discriminator_beta_1, train_config.discriminator_beta_2),\n",
    "                                   weight_decay=train_config.discriminator_weight_decay)\n",
    "\n",
    "    g_optimizer = torch.optim.Adam(list(net.encoder.parameters()) + list(net.generator.parameters()),\n",
    "                                   lr=train_config.generator_lr,\n",
    "                                   betas=(train_config.generator_beta_1, train_config.generator_beta_2),\n",
    "                                   weight_decay=train_config.generator_weight_decay)\n",
    "    g_scheduler = torch.optim.lr_scheduler.LambdaLR(g_optimizer,\n",
    "                                                    lambda epoch: (\n",
    "                                                                          train_config.train_epochs - epoch) / train_config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    d_scheduler = torch.optim.lr_scheduler.LambdaLR(d_optimizer,\n",
    "                                                    lambda epoch: (\n",
    "                                                                          train_config.train_epochs - epoch) / train_config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    trainer = BiGANTrainer(model=net,\n",
    "                           criterion=criterion,\n",
    "                           train_loader=train_dataloader,\n",
    "                           test_loader=None,\n",
    "                           epochs=train_config.train_epochs,\n",
    "                           optimizer_generator=g_optimizer,\n",
    "                           optimizer_discriminator=d_optimizer,\n",
    "                           scheduler_gen=g_scheduler,\n",
    "                           scheduler_disc=d_scheduler,\n",
    "                           best_loss_action=lambda m, l: save_best_loss_model(model_name, m, l))\n",
    "    losses = trainer.train_bigan()\n",
    "\n",
    "    logging.info(\"completed training\")\n",
    "    save_training_plot(losses['discriminator_loss'],\n",
    "                       losses['generator_loss'],\n",
    "                       \"Golden Age Face BiGAN Losses\",\n",
    "                       base_dir + 'playground/bigan/' + f'results/bigan_plot.png')\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, discriminator_loss 0.6095, generator_loss -0.5989: 100%|██████████| 70000/70000 [00:10<00:00, 6607.40it/s]\n",
      "Epoch 1, discriminator_loss 0.4447, generator_loss -0.4326: 100%|██████████| 70000/70000 [00:10<00:00, 6926.97it/s]\n",
      "Epoch 2, discriminator_loss 0.4084, generator_loss -0.3868: 100%|██████████| 70000/70000 [00:09<00:00, 7043.41it/s]\n",
      "Epoch 3, discriminator_loss 0.3390, generator_loss -0.3093: 100%|██████████| 70000/70000 [00:09<00:00, 7108.27it/s]\n",
      "Epoch 4, discriminator_loss 0.2163, generator_loss -0.2167: 100%|██████████| 70000/70000 [00:09<00:00, 7204.62it/s]\n",
      "Epoch 5, discriminator_loss nan, generator_loss nan: 100%|██████████| 70000/70000 [00:09<00:00, 7156.34it/s]       \n",
      "Epoch 6, discriminator_loss nan, generator_loss nan: 100%|██████████| 70000/70000 [00:10<00:00, 6911.76it/s]\n",
      "Epoch 7, discriminator_loss nan, generator_loss nan: 100%|██████████| 70000/70000 [00:09<00:00, 7063.84it/s]\n",
      "Epoch 8, discriminator_loss nan, generator_loss nan: 100%|██████████| 70000/70000 [00:09<00:00, 7018.44it/s]\n",
      "Epoch 9, discriminator_loss nan, generator_loss nan:  44%|████▍     | 30976/70000 [00:04<00:05, 7086.04it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-56b4cca75f3d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# visualize_golden_age_face_data()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# model = train_bigan(get_dt_string() + \"_model\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_golden_age_face_bigan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_dt_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"_model\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;31m# torch.save(model, base_dir + 'playground/bigan/results/' + \"test_model.pth\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# model = torch.load(\"test_model.pth\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-3d1b10daa7f2>\u001B[0m in \u001B[0;36mtrain_golden_age_face_bigan\u001B[0;34m(model_name)\u001B[0m\n\u001B[1;32m     31\u001B[0m                            \u001B[0mscheduler_disc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0md_scheduler\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m                            best_loss_action=lambda m, l: save_best_loss_model(model_name, m, l))\n\u001B[0;32m---> 33\u001B[0;31m     \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_bigan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"completed training\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/AF-GAN/training/bigan_trainer.py\u001B[0m in \u001B[0;36mtrain_bigan\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     56\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquiet\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m                 \u001B[0mpbar\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m                 \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mptu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    433\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 435\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    436\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    473\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 475\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    476\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    477\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/AF-GAN/data/datasets/ffhq_dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasource\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_item\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    102\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m         \"\"\"\n\u001B[0;32m--> 104\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \"\"\"\n\u001B[0;32m---> 63\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF_pil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_pil_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_is_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pic should be PIL Image or ndarray. Got {}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py\u001B[0m in \u001B[0;36m_is_pil_image\u001B[0;34m(img)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "# visualize_data()\n",
    "# visualize_golden_age_face_data()\n",
    "# model = train_bigan(get_dt_string() + \"_model\")\n",
    "model = train_golden_age_face_bigan(get_dt_string() + \"_model\")\n",
    "# torch.save(model, base_dir + 'playground/bigan/results/' + \"test_model.pth\")\n",
    "# model = torch.load(\"test_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image: 512\n",
      "reading image: 1024\n",
      "reading image: 1536\n",
      "reading image: 2048\n",
      "reading image: 2560\n",
      "reading image: 3072\n",
      "reading image: 3584\n",
      "reading image: 4096\n",
      "reading image: 4608\n",
      "reading image: 5120\n",
      "reading image: 5632\n",
      "reading image: 6144\n",
      "reading image: 6656\n",
      "reading image: 7168\n",
      "reading image: 7680\n",
      "reading image: 8192\n",
      "reading image: 8704\n",
      "reading image: 9216\n",
      "reading image: 9728\n",
      "reading image: 10240\n",
      "reading image: 10752\n",
      "reading image: 11264\n",
      "reading image: 11776\n",
      "reading image: 12288\n",
      "reading image: 12800\n",
      "reading image: 13312\n",
      "reading image: 13824\n",
      "reading image: 14336\n",
      "reading image: 14848\n",
      "reading image: 15360\n",
      "reading image: 15872\n",
      "reading image: 16384\n",
      "reading image: 16896\n",
      "reading image: 17408\n",
      "reading image: 17920\n",
      "reading image: 18432\n",
      "reading image: 18944\n",
      "reading image: 19456\n",
      "reading image: 19968\n",
      "reading image: 20480\n",
      "reading image: 20992\n",
      "reading image: 21504\n",
      "reading image: 22016\n",
      "reading image: 22528\n",
      "reading image: 23040\n",
      "reading image: 23552\n",
      "reading image: 24064\n",
      "reading image: 24576\n",
      "reading image: 25088\n",
      "reading image: 25600\n",
      "reading image: 26112\n",
      "reading image: 26624\n",
      "reading image: 27136\n",
      "reading image: 27648\n",
      "reading image: 28160\n",
      "reading image: 28672\n",
      "reading image: 29184\n",
      "reading image: 29696\n"
     ]
    }
   ],
   "source": [
    "config = read_config(Config.BiGAN)\n",
    "train_dataset = FFHQDataset(\n",
    "datasource=FFHQDatasource(config, mode=DataSourceMode.TRAIN))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train_bigan(model_name='test_model'):\n",
    "    logging.info(\"initiate training\")\n",
    "    net = BiGAN(image_dim=config.image_dim, latent_dim=config.latent_dim_z).to(ptu.device)\n",
    "    criterion = BidirectionalDiscriminatorLoss(loss_type=BidirectionalDiscriminatorLossType.VANILLA_LOG_MEAN)\n",
    "\n",
    "    d_optimizer = torch.optim.Adam(net.discriminator.parameters(),\n",
    "                                   lr=config.discriminator_lr,\n",
    "                                   betas=(config.discriminator_beta_1, config.discriminator_beta_2),\n",
    "                                   weight_decay=config.discriminator_weight_decay)\n",
    "\n",
    "    g_optimizer = torch.optim.Adam(list(net.encoder.parameters()) + list(net.generator.parameters()),\n",
    "                                   lr=config.generator_lr,\n",
    "                                   betas=(config.generator_beta_1, config.generator_beta_2),\n",
    "                                   weight_decay=config.generator_weight_decay)\n",
    "    g_scheduler = torch.optim.lr_scheduler.LambdaLR(g_optimizer,\n",
    "                                                    lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    d_scheduler = torch.optim.lr_scheduler.LambdaLR(d_optimizer,\n",
    "                                                    lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    trainer = BiGANTrainer(model=net,\n",
    "                           criterion=criterion,\n",
    "                           train_loader=train_dataloader,\n",
    "                           test_loader=None,\n",
    "                           epochs=config.train_epochs,\n",
    "                           optimizer_generator=g_optimizer,\n",
    "                           optimizer_discriminator=d_optimizer,\n",
    "                           scheduler_gen=g_scheduler,\n",
    "                           scheduler_disc=d_scheduler,\n",
    "                           best_loss_action=lambda m, l: save_best_loss_model(model_name, m, l))\n",
    "    losses = trainer.train_bigan()\n",
    "\n",
    "    logging.info(\"completed training\")\n",
    "    save_training_plot(losses['discriminator_loss'],\n",
    "                       losses['generator_loss'],\n",
    "                       \"BiGAN Losses\",\n",
    "                       base_dir + 'playground/bigan/' + f'results/bigan_plot.png')\n",
    "    return net\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, discriminator_loss 0.3721, generator_loss -0.3500: 100%|██████████| 30000/30000 [00:11<00:00, 2568.16it/s]\n",
      "Epoch 1, discriminator_loss 0.2520, generator_loss -0.2198: 100%|██████████| 30000/30000 [00:11<00:00, 2676.11it/s]\n",
      "Epoch 2, discriminator_loss 0.2141, generator_loss -0.1978: 100%|██████████| 30000/30000 [00:11<00:00, 2586.64it/s]\n",
      "Epoch 3, discriminator_loss 0.2127, generator_loss -0.1976: 100%|██████████| 30000/30000 [00:12<00:00, 2471.59it/s]\n",
      "Epoch 4, discriminator_loss 0.2586, generator_loss -0.2358: 100%|██████████| 30000/30000 [00:11<00:00, 2637.02it/s]\n",
      "Epoch 5, discriminator_loss 0.3061, generator_loss -0.2855: 100%|██████████| 30000/30000 [00:11<00:00, 2677.30it/s]\n",
      "Epoch 6, discriminator_loss 0.1795, generator_loss -0.1662: 100%|██████████| 30000/30000 [00:11<00:00, 2571.36it/s]\n",
      "Epoch 7, discriminator_loss 0.1665, generator_loss -0.1419: 100%|██████████| 30000/30000 [00:11<00:00, 2598.64it/s]\n",
      "Epoch 8, discriminator_loss 0.0376, generator_loss -0.0353: 100%|██████████| 30000/30000 [00:11<00:00, 2527.77it/s]\n",
      "Epoch 9, discriminator_loss 0.0442, generator_loss -0.0513: 100%|██████████| 30000/30000 [00:11<00:00, 2525.91it/s]\n",
      "Epoch 10, discriminator_loss 0.1138, generator_loss -0.0956: 100%|██████████| 30000/30000 [00:11<00:00, 2626.44it/s]\n",
      "Epoch 11, discriminator_loss 0.0247, generator_loss -0.0378: 100%|██████████| 30000/30000 [00:11<00:00, 2631.36it/s]\n",
      "Epoch 12, discriminator_loss 0.1084, generator_loss -0.0933: 100%|██████████| 30000/30000 [00:11<00:00, 2566.33it/s]\n",
      "Epoch 13, discriminator_loss 0.0629, generator_loss -0.0578: 100%|██████████| 30000/30000 [00:11<00:00, 2551.21it/s]\n",
      "Epoch 14, discriminator_loss 0.0919, generator_loss -0.0759: 100%|██████████| 30000/30000 [00:12<00:00, 2499.31it/s]\n",
      "Epoch 15, discriminator_loss 0.0438, generator_loss -0.0458: 100%|██████████| 30000/30000 [00:11<00:00, 2562.10it/s]\n",
      "Epoch 16, discriminator_loss 0.0931, generator_loss -0.0718: 100%|██████████| 30000/30000 [00:11<00:00, 2645.28it/s]\n",
      "Epoch 17, discriminator_loss 0.0109, generator_loss -0.0104: 100%|██████████| 30000/30000 [00:11<00:00, 2637.73it/s]\n",
      "Epoch 18, discriminator_loss 0.0718, generator_loss -0.0620: 100%|██████████| 30000/30000 [00:11<00:00, 2638.68it/s]\n",
      "Epoch 19, discriminator_loss 0.0280, generator_loss -0.0268: 100%|██████████| 30000/30000 [00:11<00:00, 2527.50it/s]\n",
      "Epoch 20, discriminator_loss 0.2231, generator_loss -0.1838: 100%|██████████| 30000/30000 [00:11<00:00, 2534.24it/s]\n",
      "Epoch 21, discriminator_loss 0.0204, generator_loss -0.0204: 100%|██████████| 30000/30000 [00:11<00:00, 2526.73it/s]\n",
      "Epoch 22, discriminator_loss 0.0093, generator_loss -0.0092: 100%|██████████| 30000/30000 [00:11<00:00, 2519.81it/s]\n",
      "Epoch 23, discriminator_loss 0.0509, generator_loss -0.0455: 100%|██████████| 30000/30000 [00:11<00:00, 2656.40it/s]\n",
      "Epoch 24, discriminator_loss 0.0662, generator_loss -0.0538: 100%|██████████| 30000/30000 [00:11<00:00, 2654.34it/s]\n",
      "Epoch 25, discriminator_loss 0.1561, generator_loss -0.1130: 100%|██████████| 30000/30000 [00:11<00:00, 2660.11it/s]\n",
      "Epoch 26, discriminator_loss 0.0273, generator_loss -0.0331: 100%|██████████| 30000/30000 [00:11<00:00, 2549.13it/s]\n",
      "Epoch 27, discriminator_loss 0.0282, generator_loss -0.0253: 100%|██████████| 30000/30000 [00:11<00:00, 2634.11it/s]\n",
      "Epoch 28, discriminator_loss 0.0145, generator_loss -0.0136: 100%|██████████| 30000/30000 [00:11<00:00, 2645.03it/s]\n",
      "Epoch 29, discriminator_loss 0.0218, generator_loss -0.0178: 100%|██████████| 30000/30000 [00:11<00:00, 2645.92it/s]\n",
      "Epoch 30, discriminator_loss 0.0113, generator_loss -0.0110: 100%|██████████| 30000/30000 [00:11<00:00, 2645.42it/s]\n",
      "Epoch 31, discriminator_loss 0.0110, generator_loss -0.0104: 100%|██████████| 30000/30000 [00:11<00:00, 2641.25it/s]\n",
      "Epoch 32, discriminator_loss 0.0065, generator_loss -0.0062: 100%|██████████| 30000/30000 [00:11<00:00, 2641.93it/s]\n",
      "Epoch 33, discriminator_loss 0.0696, generator_loss -0.0569: 100%|██████████| 30000/30000 [00:11<00:00, 2643.02it/s]\n",
      "Epoch 34, discriminator_loss 0.0066, generator_loss -0.0065: 100%|██████████| 30000/30000 [00:11<00:00, 2640.57it/s]\n",
      "Epoch 35, discriminator_loss 0.0044, generator_loss -0.0043: 100%|██████████| 30000/30000 [00:11<00:00, 2646.96it/s]\n",
      "Epoch 36, discriminator_loss 0.0075, generator_loss -0.0065: 100%|██████████| 30000/30000 [00:11<00:00, 2637.99it/s]\n",
      "Epoch 37, discriminator_loss 0.0032, generator_loss -0.0032: 100%|██████████| 30000/30000 [00:11<00:00, 2636.70it/s]\n",
      "Epoch 38, discriminator_loss 0.0026, generator_loss -0.0026: 100%|██████████| 30000/30000 [00:11<00:00, 2643.80it/s]\n",
      "Epoch 39, discriminator_loss 0.0039, generator_loss -0.0042: 100%|██████████| 30000/30000 [00:11<00:00, 2650.20it/s]\n",
      "Epoch 40, discriminator_loss 0.0358, generator_loss -0.0235: 100%|██████████| 30000/30000 [00:11<00:00, 2651.03it/s]\n",
      "Epoch 41, discriminator_loss 0.0239, generator_loss -0.0181: 100%|██████████| 30000/30000 [00:11<00:00, 2648.38it/s]\n",
      "Epoch 42, discriminator_loss 0.0349, generator_loss -0.0410: 100%|██████████| 30000/30000 [00:11<00:00, 2650.22it/s]\n",
      "Epoch 43, discriminator_loss 0.0115, generator_loss -0.0087: 100%|██████████| 30000/30000 [00:11<00:00, 2652.47it/s]\n",
      "Epoch 44, discriminator_loss 0.0248, generator_loss -0.0206: 100%|██████████| 30000/30000 [00:11<00:00, 2645.22it/s]\n",
      "Epoch 45, discriminator_loss 0.0340, generator_loss -0.0214: 100%|██████████| 30000/30000 [00:11<00:00, 2642.56it/s]\n",
      "Epoch 46, discriminator_loss 0.0297, generator_loss -0.0244: 100%|██████████| 30000/30000 [00:11<00:00, 2650.86it/s]\n",
      "Epoch 47, discriminator_loss 0.0500, generator_loss -0.0358: 100%|██████████| 30000/30000 [00:11<00:00, 2647.87it/s]\n",
      "Epoch 48, discriminator_loss 0.0163, generator_loss -0.0201: 100%|██████████| 30000/30000 [00:11<00:00, 2638.27it/s]\n",
      "Epoch 49, discriminator_loss 0.0073, generator_loss -0.0174: 100%|██████████| 30000/30000 [00:11<00:00, 2646.04it/s]\n",
      "Epoch 50, discriminator_loss 0.0092, generator_loss -0.0073: 100%|██████████| 30000/30000 [00:11<00:00, 2651.29it/s]\n",
      "Epoch 51, discriminator_loss 0.0086, generator_loss -0.0079: 100%|██████████| 30000/30000 [00:11<00:00, 2650.02it/s]\n",
      "Epoch 52, discriminator_loss 0.0038, generator_loss -0.0035: 100%|██████████| 30000/30000 [00:11<00:00, 2652.38it/s]\n",
      "Epoch 53, discriminator_loss 0.0489, generator_loss -0.0575: 100%|██████████| 30000/30000 [00:11<00:00, 2655.64it/s]\n",
      "Epoch 54, discriminator_loss 0.0119, generator_loss -0.0115: 100%|██████████| 30000/30000 [00:11<00:00, 2655.16it/s]\n",
      "Epoch 55, discriminator_loss 0.0145, generator_loss -0.0115: 100%|██████████| 30000/30000 [00:11<00:00, 2652.25it/s]\n",
      "Epoch 56, discriminator_loss 0.0574, generator_loss -0.0699: 100%|██████████| 30000/30000 [00:11<00:00, 2649.32it/s]\n",
      "Epoch 57, discriminator_loss 0.0073, generator_loss -0.0068: 100%|██████████| 30000/30000 [00:11<00:00, 2645.13it/s]\n",
      "Epoch 58, discriminator_loss 0.0102, generator_loss -0.0080: 100%|██████████| 30000/30000 [00:11<00:00, 2648.78it/s]\n",
      "Epoch 59, discriminator_loss 0.0079, generator_loss -0.0058: 100%|██████████| 30000/30000 [00:11<00:00, 2648.18it/s]\n",
      "Epoch 60, discriminator_loss 0.0054, generator_loss -0.0049: 100%|██████████| 30000/30000 [00:11<00:00, 2647.66it/s]\n",
      "Epoch 61, discriminator_loss 0.0343, generator_loss -0.0357: 100%|██████████| 30000/30000 [00:11<00:00, 2657.38it/s]\n",
      "Epoch 62, discriminator_loss 0.0146, generator_loss -0.0114: 100%|██████████| 30000/30000 [00:11<00:00, 2644.59it/s]\n",
      "Epoch 63, discriminator_loss 0.0381, generator_loss -0.0388: 100%|██████████| 30000/30000 [00:11<00:00, 2641.78it/s]\n",
      "Epoch 64, discriminator_loss 0.0158, generator_loss -0.0139: 100%|██████████| 30000/30000 [00:11<00:00, 2651.14it/s]\n",
      "Epoch 65, discriminator_loss 0.0058, generator_loss -0.0054: 100%|██████████| 30000/30000 [00:11<00:00, 2649.87it/s]\n",
      "Epoch 66, discriminator_loss 0.0036, generator_loss -0.0035: 100%|██████████| 30000/30000 [00:11<00:00, 2645.94it/s]\n",
      "Epoch 67, discriminator_loss 0.0056, generator_loss -0.0053: 100%|██████████| 30000/30000 [00:11<00:00, 2637.36it/s]\n",
      "Epoch 68, discriminator_loss 0.0062, generator_loss -0.0065: 100%|██████████| 30000/30000 [00:11<00:00, 2637.76it/s]\n",
      "Epoch 69, discriminator_loss 0.0040, generator_loss -0.0030: 100%|██████████| 30000/30000 [00:11<00:00, 2640.39it/s]\n",
      "Epoch 70, discriminator_loss 0.0121, generator_loss -0.0137: 100%|██████████| 30000/30000 [00:11<00:00, 2649.91it/s]\n",
      "Epoch 71, discriminator_loss 0.0170, generator_loss -0.0142: 100%|██████████| 30000/30000 [00:11<00:00, 2646.71it/s]\n",
      "Epoch 72, discriminator_loss 0.0113, generator_loss -0.0097: 100%|██████████| 30000/30000 [00:11<00:00, 2644.84it/s]\n",
      "Epoch 73, discriminator_loss 0.0104, generator_loss -0.0099: 100%|██████████| 30000/30000 [00:11<00:00, 2635.90it/s]\n",
      "Epoch 74, discriminator_loss 0.0067, generator_loss -0.0069: 100%|██████████| 30000/30000 [00:11<00:00, 2644.22it/s]\n",
      "Epoch 75, discriminator_loss 0.0089, generator_loss -0.0101: 100%|██████████| 30000/30000 [00:11<00:00, 2651.16it/s]\n",
      "Epoch 76, discriminator_loss 0.0096, generator_loss -0.0093: 100%|██████████| 30000/30000 [00:11<00:00, 2652.86it/s]\n",
      "Epoch 77, discriminator_loss 0.0038, generator_loss -0.0036: 100%|██████████| 30000/30000 [00:11<00:00, 2650.47it/s]\n",
      "Epoch 78, discriminator_loss 0.0031, generator_loss -0.0034: 100%|██████████| 30000/30000 [00:11<00:00, 2649.05it/s]\n",
      "Epoch 79, discriminator_loss 0.0022, generator_loss -0.0022: 100%|██████████| 30000/30000 [00:11<00:00, 2650.59it/s]\n",
      "Epoch 80, discriminator_loss 0.0042, generator_loss -0.0040: 100%|██████████| 30000/30000 [00:11<00:00, 2664.01it/s]\n",
      "Epoch 81, discriminator_loss 0.0350, generator_loss -0.0246: 100%|██████████| 30000/30000 [00:11<00:00, 2652.87it/s]\n",
      "Epoch 82, discriminator_loss 0.0110, generator_loss -0.0089: 100%|██████████| 30000/30000 [00:11<00:00, 2650.66it/s]\n",
      "Epoch 83, discriminator_loss 0.0138, generator_loss -0.0086: 100%|██████████| 30000/30000 [00:11<00:00, 2651.83it/s]\n",
      "Epoch 84, discriminator_loss 0.0061, generator_loss -0.0056: 100%|██████████| 30000/30000 [00:11<00:00, 2652.85it/s]\n",
      "Epoch 85, discriminator_loss 0.0052, generator_loss -0.0047: 100%|██████████| 30000/30000 [00:11<00:00, 2653.69it/s]\n",
      "Epoch 86, discriminator_loss 0.0033, generator_loss -0.0030: 100%|██████████| 30000/30000 [00:11<00:00, 2656.08it/s]\n",
      "Epoch 87, discriminator_loss 0.0054, generator_loss -0.0047: 100%|██████████| 30000/30000 [00:11<00:00, 2654.87it/s]\n",
      "Epoch 88, discriminator_loss 0.0031, generator_loss -0.0029: 100%|██████████| 30000/30000 [00:11<00:00, 2652.68it/s]\n",
      "Epoch 89, discriminator_loss 0.0047, generator_loss -0.0044: 100%|██████████| 30000/30000 [00:11<00:00, 2657.61it/s]\n",
      "Epoch 90, discriminator_loss 0.0059, generator_loss -0.0051: 100%|██████████| 30000/30000 [00:11<00:00, 2658.03it/s]\n",
      "Epoch 91, discriminator_loss 0.0051, generator_loss -0.0050: 100%|██████████| 30000/30000 [00:11<00:00, 2652.24it/s]\n",
      "Epoch 92, discriminator_loss 0.0053, generator_loss -0.0050: 100%|██████████| 30000/30000 [00:11<00:00, 2658.49it/s]\n",
      "Epoch 93, discriminator_loss 0.0055, generator_loss -0.0053: 100%|██████████| 30000/30000 [00:11<00:00, 2649.21it/s]\n",
      "Epoch 94, discriminator_loss 0.0049, generator_loss -0.0044: 100%|██████████| 30000/30000 [00:11<00:00, 2644.09it/s]\n",
      "Epoch 95, discriminator_loss 0.0051, generator_loss -0.0049: 100%|██████████| 30000/30000 [00:11<00:00, 2620.78it/s]\n",
      "Epoch 96, discriminator_loss 0.0039, generator_loss -0.0037: 100%|██████████| 30000/30000 [00:11<00:00, 2636.69it/s]\n",
      "Epoch 97, discriminator_loss 0.0049, generator_loss -0.0047: 100%|██████████| 30000/30000 [00:11<00:00, 2643.80it/s]\n",
      "Epoch 98, discriminator_loss 0.0041, generator_loss -0.0041: 100%|██████████| 30000/30000 [00:11<00:00, 2648.52it/s]\n",
      "Epoch 99, discriminator_loss 0.0051, generator_loss -0.0041: 100%|██████████| 30000/30000 [00:11<00:00, 2655.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEYCAYAAAD4czk4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9PklEQVR4nO3dd5hU1fnA8e+7hV16VylSrUiVRVGTIGoQxRaNHVuMRk38WRIFosEWYy/BoAYTNIk9GksEFVGqEREQlN6RzlJ2YYGFLef3x72zOzs7fe7MvTPzfp5nn525c8u5U857T7nniDEGpZRSykty3E6AUkopFUiDk1JKKc/R4KSUUspzNDgppZTyHA1OSimlPEeDk1JKKc/R4KSUTUReFJE/uJ0OpZQGJ5VFRGStiOwXkTIR2SUiE0TkcN/rxpibjDEP+a3fVESetrfbKyI/iMg7InJCwH5FRFaLyOIgx5wqIuX+xxGRM0RkbZh0GhE5IuETViqNaXBS2eZcY0wToB2wFXgu2EoiUgB8AfQCzgGaAccCbwJnB6z+E+AQoJuIDAiyu72AlsiUioEGJ5WVjDHlwDtAD98yEXlFRP5oP70K6AhcYIxZaIypMsbsNca8Y4y5P2B31wAfABPtx4HGAJcnWhoSkeYi8k8RKRaRdSJyr4jk2K8dISLTRKRURLaLyFv2chGRZ0Rkm/3adyLS036tQESetEuEW+1qzYb2a21E5CMRKRGRnSIyw3cspVJBv2wqK4lII+BSYFaIVc4APjXG7I1iPz8HXrP/LhORBgGrbQReAu5PJM1YpbzmQDdgEHA1cJ392kPAJKAlVlD1lQiHYJXsjgJaYJ3zDvu1x+zlfYEjgA7AaPu13wIbgLbAocDvAR3rTKWMBieVbd4XkRJgN/BT4IkQ67UBtvieiEhfuxSxW0SW+a13IXAAKzB8BOQBw4Ls7xHgXBE5Lp5Ei0guVmAZZYzZY4xZCzyFVcIDqAA6A+2NMeXGmJl+y5sCxwBijFlijNksIgLcANxhjNlpjNkD/Am4zG+7dkBnY0yFMWaG0YE4VQppcFLZ5gJjTAugAPgNME1EDguy3g6szBkAY8x8e7sL7W19rgHeNsZUGmMOAP8hSNWeMaYY+AvwYJzpbgM0ANb5LVuHVdoBuBsQYLaILBKRX9jH/cI+7lhgq4iME5FmWCWiRsBcO+iWAJ/Yy8EK2iuBSXZnj5FxplupuGhwUlnJbkP6D1AF/CjIKp8DQ0Skcah9iEhH4DRguIhsEZEtWFV8Z4tImyCbPAEMBvrHkeTt1JaOfDphVRlijNlijLnBGNMe+BXwvK+NyxgzxhjTHzgOqxrvLnt/+4HjjDEt7L/mdmcR7NLZb40x3YBzgTtF5PQ40q1UXDQ4qaxkdxQ4H6uNZkmQVf4JbAbeE5GeIpIrIoVAkd86VwHLgaOx2m36YmX+G4DLA3dojCnBqoq7O4okNhCRQt+fvext4GG7i3tn4E7gVft8LraDJcAurPahKhEZICInikg+Vq/BcqDKGFON1Q72jIgcYu+jg4icaT8+x+5kIVhVoFX2n1IpocFJZZv/ikgZVob7MHCNMWZR4Ep2b77BwGJggr3+MmAAcIm92jXA83appeYPeJHgvfYA/kx0mfwirJKN7+864FasALMamAm8Doy31x8AfG2f24fAbcaYNVhd4F/CCljrsKorn7S3GYFVdTdLRHYDk7ECLcCR9vMy4Cv7PKdGkW6lHCHaxqmUUsprtOSklFLKczQ4KaWU8hwNTkoppTxHg5NSSinPyXM7AbFo06aN6dKli9vJUEopFYe5c+duN8a0jbxmmgWnLl26MGfOHLeToZRSKg4isi7yWhat1lNKKeU5GpyUUkp5jgYnpZRSnpNWbU5KKZVsFRUVbNiwgfLycreTkrYKCwvp2LEj+fn5ce9Dg5NSSvnZsGEDTZs2pUuXLljj3qpYGGPYsWMHGzZsoGvXrnHvR6v1lFLKT3l5Oa1bt9bAFCcRoXXr1gmXPDU4KaVUAA1MiXHi/dPgpFQaW7C+hLIDlW4nQynHaXBSKk3tO1jJ+WO/5OZX57qdFOWgkpISnn/++bi2PfvssykpKYl6/fvvv58nn3wy8oou0OCkVJqqqLTmYluwvsTdhChHhQtOVVXh56mcOHEiLVq0SEKqUk+Dk1JKecjIkSNZtWoVffv25a677mLq1KkMHjyYK664gl69egFwwQUX0L9/f4477jjGjRtXs22XLl3Yvn07a9eu5dhjj+WGG27guOOOY8iQIezfvz/scefPn8/AgQPp3bs3P/vZz9i1axcAY8aMoUePHvTu3ZvLLrsMgGnTptG3b1/69u1Lv3792LNnj+Pvg3YlVyrN6VzWyfPAfxexeNNuR/fZo30z7jv3uJCvP/rooyxcuJD58+cDMHXqVGbPns3ChQtrumaPHz+eVq1asX//fgYMGMBFF11E69at6+xnxYoVvPHGG7z00ktccsklvPvuuwwfPjzkca+++mqee+45Bg0axOjRo3nggQd49tlnefTRR1mzZg0FBQU1VYZPPvkkY8eO5ZRTTqGsrIzCwsLE3pQgtOSkVLrSDmVZ44QTTqhzz9CYMWPo06cPAwcOZP369axYsaLeNl27dqVv374A9O/fn7Vr14bcf2lpKSUlJQwaNAiAa665hunTpwPQu3dvrrzySl599VXy8qzyzCmnnMKdd97JmDFjKCkpqVnuJNdKTiJyOPBP4DCgGhhnjPmzW+lRSqlA4Uo4qdS4ceOax1OnTmXy5Ml89dVXNGrUiFNPPTXoPUUFBQU1j3NzcyNW64UyYcIEpk+fzocffshDDz3EokWLGDlyJMOGDWPixIkMHDiQyZMnc8wxx8S1/1DcLDlVAr81xhwLDAR+LSI9XEyPUulJ6/UyStOmTcO24ZSWltKyZUsaNWrE0qVLmTVrVsLHbN68OS1btmTGjBkA/Otf/2LQoEFUV1ezfv16Bg8ezOOPP05JSQllZWWsWrWKXr16MWLECIqKili6dGnCaQjkWsnJGLMZ2Gw/3iMiS4AOwGK30qRUOtH7RDNT69atOeWUU+jZsydnnXUWw4YNq/P60KFDefHFF+nduzdHH300AwcOdOS4//jHP7jpppvYt28f3bp14+WXX6aqqorhw4dTWlqKMYY77riDFi1a8Ic//IEpU6aQm5tLjx49OOussxxJgz8xxv3LLhHpAkwHehpjQrY+FhUVGZ1sUCnL7vIKet8/iaYFeXz/wJluJydjLFmyhGOPPdbtZKS9YO+jiMw1xhRFs73rHSJEpAnwLnB7sMAkIjeKyBwRmVNcXJz6BCqllEo5V4OTiORjBabXjDH/CbaOMWacMabIGFPUtm1UU88rlVXcr/tQynmuBSexRgb8O7DEGPO0W+lQKl3F0uQ08fvNrN+5L2lpUcppbpacTgGuAk4Tkfn239kupkeptBJLiemW1+Zx9pgZSUuLUk5zs7feTPQ2QqVSZk+5jl6u0ofrHSKUUvHRKzuVyTQ4KaWUhyQyZQbAs88+y759wdsXTz31VNLldhwNTkqlOS/cq6ick8zglE40OCmVpnQq8cwUOGUGwBNPPMGAAQPo3bs39913HwB79+5l2LBh9OnTh549e/LWW28xZswYNm3axODBgxk8eHDY47zxxhv06tWLnj17MmLECMCaL+raa6+lZ8+e9OrVi2eeeQYIPm1GsumUGUopFcrHI2HL987u87BecNajIV8OnDJj0qRJrFixgtmzZ2OM4bzzzmP69OkUFxfTvn17JkyYAFhj7jVv3pynn36aKVOm0KZNm5DH2LRpEyNGjGDu3Lm0bNmSIUOG8P7773P44YezceNGFi5cCFAzRUawaTOSTUtOWaKyqprxM9dwsLLa7aQkbEfZAa3K8qPvRGabNGkSkyZNol+/fhx//PEsXbqUFStW0KtXLyZPnsyIESOYMWMGzZs3j3qf33zzDaeeeipt27YlLy+PK6+8kunTp9OtWzdWr17NrbfeyieffEKzZs2A4NNmJJuWnLLEW3PW8+BHi9l7oJJbTz/S7eTEbc32vQx+cir3DjuWX/64m9vJcZVXKvWWbdnDjBXFmfl5hCnhpIoxhlGjRvGrX/2q3mtz585l4sSJjBo1iiFDhjB69Oio9xlMy5YtWbBgAZ9++iljx47l7bffZvz48UGnzUh2kNKSU5Yos+9x2XMgve91+cEe5WDach1n0SvOeW4Gf5ywxO1kZIzAKTPOPPNMxo8fT1lZGQAbN25k27ZtbNq0iUaNGjF8+HB+97vfMW/evKDbB3PiiScybdo0tm/fTlVVFW+88QaDBg1i+/btVFdXc9FFF/HQQw8xb968kNNmJJuWnJRKc6mo4TTG8N63Gzm3T3vyc+te01ZUacWikwKnzHjiiSdYsmQJJ510EgBNmjTh1VdfZeXKldx1113k5OSQn5/PCy+8AMCNN97IWWedRbt27ZgyZUrQY7Rr145HHnmEwYMHY4zh7LPP5vzzz2fBggVcd911VFdb1f+PPPJIyGkzkk2Dk1JpKpWd9T5csIk7317Axl3707paOF28/vrrdZ7fdttt3HbbbXWWde/enTPPrD9Vyq233sqtt94adL9Tp06teXzFFVdwxRVX1Hm9T58+NSUwfzNnzow26Y7Raj2lVES79h4EYHvZAZdTorKFBqcsd9Q9H/PYJ85PsaySTzssqkymwSnLHayq5oWpq9xOhlKeorcqJMaJ90+Dk1Jpyo0BIrIhyy4sLGTHjh0aoOJkjGHHjh0UFhYmtB/tEKGUiiibhkrq2LEjGzZsoLhYb1eIV2FhIR07dkxoHxqclEpzJivKM6mTn59P165d3U5G1tNqPaWUI7QaTDlJg5NSKmoaf1SqaHDyqOpqww87nJ+TRa9uM49+pCoTaXDyqDFfrOAnT0xhdXHyx7BSKlrh+kVokFRO0uDkIVOWbeOThVsAmLV6BwBbdpc7eoxQva5WF5ex/2CVo8dSSql4aXDykOte/oabXp1bd2GKrkZPe2oat7w2N/KKynNSWWDR0pFKFQ1OWSZcm9OXK3ekMCUqnWTRbU7KIzQ4KaUcoYUq5SQNTh4lSZrnNNyd/nozZ3rRKjaVyTQ4KaWiphcwKlU0OKWhj7/fTHlFfD3rwrU56ZW4CiWacrzeQ6ecpMHJzyV//Yr3vt3gdjLC+mbtTm5+bR4PT1hS77X560uYs3anC6lSmU7Djko1HfjVz+w1O5m9Zic/65fYaLpOCswUSvdVALCxZH+9dS8Y+yUAax8dFnJ/4dqctEdWmkph5EhWW6hSgbTklGZ8ASQZVShaK6MiCdfmpF8f5SQNTmkm0dKNtguoeGh5SaWaBiePihSEYg0x0QQ1DVvpSXvQqUzkanASkfEisk1EFrqZDqdtLNnPgvUlSdl3vHX+mVJg0it478qU75jyBrdLTq8AQ11Og+NOefQLzrc7JyRLvBlBuk+3nS7539tz1tNl5AS2Ojxwr9s0AKlUcTU4GWOmA9r3ORa+DhFxbq5tTqnxzlzrloQ12/cm/Vgp+UjT/KJGpR+3S04RiciNIjJHROYUFxen5JjV1cYzmXhgMuLNIjRvcYdHvkYpoW1fykmeD07GmHHGmCJjTFHbtm0d3XdlVTWVVdX1lnf7/UTufd/bzWCxBs9oVvdKQM4EqbgWSOmnpd8NlWKeD07JVPTwZIoengzUz5hf+/oHN5IUUaJtRune5pRutDShVHyyeoSIEnu0BWOM5y4MQ8WQREOLlo5SI+OuATLuhJTXud2V/A3gK+BoEdkgIte7kY6XZqx247AppXmLSja97lFOcru33uXGmHbGmHxjTEdjzN/dSMefJi5Nu8qXWDOCaNavTrc3IR1kwXuqFz4qGbK2zansQGWd55Gqu4wxPPLxEpZv3eNYGl6dtY5PFm6OaZuasfXizPWS0eZ0oLKKi1/8X9JuPPaXLvlgKgdITWX8y4JYqzwia4NTvwcn1Xke6Ue3Y+9B/jptNVe89LVjabj3/YXc9Oq8sOsEBiFfphdvFUoy2pyWbt7DN2t38YcPkt/DMd0yx3RLbyjpclGgMkdWBadfvz6PSYu2AFBRVTfbiDbPrrZXXL9zHwcq45vwLxHxFnycLDB9MH8jxXsO1FuubQ61sqmqK4tOVaVQ1gQnYwwTvtvMjf+aG9f2OeIrsRjKK6r48eNTuOvf3zmZxLSwa+9BbntzPte9MrtmWaJVjZksFQFbe2CqTJQ1welgkJtt/UXKWH1Xh9UGDlRY+5q6bJsTSQtxvPDXo8noEBGNimrr3JdvLeOOt+azu7zCmR1HKRlX6Us27+av01YlYc+ZJ9z3SGOkclLWBKdIP5xIrydaTbN0y+6a8dYS4UuGwdBl5AQe+2RpwvuMx8HKat77diOvfLk2pcdNRv43bMwMHvm49n2ctXqHox1flFKxy5rgVJifS5+OzRl0VHxDINV2RKjNHmPJKIc+O4Pf/XtBXMcOSIidDuv/C1MjX/FXVxvmrNuV+LFDJCewk8a8H3bx1KRlSTleMgR2ob9s3CyGPDM9oX2mss0plQWWbGpLU+7KmuAE0KxhPrv2HQz6WsQqCf+gkMqMp97Ar7H31ntpxmo+W7zVwVTVKt1fwbl/mVln2YXP/4/nvliZlOMlUzLabrKpHS5bzvWFqas4bvQnbicj42VVcOrQoiGbSvYHfS3iD8vU+Re3aDPASFeo1TFkpCu2lUW9bkQBh126JbXVX8m8LnAyNqXiPic3OkIEO2S2jdf42CdL2Xsw9T11s01WBaf2LRqyvewgb3+zPu59lB2oTChCRZufRFovluDkv2qiGUngUf13l5KeaUncdyzvabQypZNAlsUf5QFZFZx2lFn35tz9bv0u4BE7TPhli8X2fuL5vSaaV/kyiaoYduSfdqevtnPC5Frp1sXZydRmY2aeZh+38risCk7DercP+Vqw31VVtaHvg5N4d+6GOj+8M56eBsDu8sogW4UX7dV5pFHJqx0YCM+J4BEuE063sfqSUXLKBlkYh1UKZFVwOq59s5CvBcuo9x6spGRfBfd9uCjsfov3HGDb7vKo0hDz/UkBz33VcjFlpEnMc/0zpsDDpFtmn4zkpuIdSO3bnF6fqUpfWRWcGheEnr4q0k8u3OsDHp7MCX/6PKo0RF9yCh+E4i2VJNzmFHDc3JzQ+0tGcEqXDhGZJpUD2Uayc+9BFm4sdTsZKsmyKjjFquaGV2Mcaz+Jdje5NV3XAwZ+9bU52SM1xBpr6tyn5cApzfuhJMyxEt9/vX06v8sayekQkRkRL5pu4qkqKZ8/dibnPDcz8ooqrWlwsoXrIuvkTy7ae0FqSk4Boy75CiqVMRSdkpll7Nxbe99YYEa8pTS6qk6v8FI15Nbd5Qx5ZlrIWx/cU/9qqHZsxdRYv9Nr74lKhqwLTk1CVe1Fd5tTwqKNKb4gFJhh+nrHVdrd9RKpbInnnMIF1+1ldUcq//vMNXEcwT3eCU3w7znrWb61jFdnrXM7KQHqv0s1F3FJegPLK6r4cuX25OxceVbWBadXf3li0OXBMt1qh6vAAvcZTk5Nm1Pd5b42nir7hVjbkOJtc6quNlRGGDx3e1nd0TcOVoZfPx7JbPmYtGgrg5+c6si+At/nzaX7OfOZ6WyNsuOM125sDdfm5F/9nQz3fbCIK//2NSs8Nt5hplTZelXWBafWjRsEXb57f/1u4b7v3r6DVezYW3/+onhE+33OCdEhwre8wg4UxhjW7dgb4ZiJ3+d02bhZHHHPxzEF6WTMd5XM7OB3/17Amu3h38tY+dL72qwfWLZ1D28lcAO4V+UkueS0YpsVlEr3p3YE/Eg0NiVX1gWnliGC0+Uvzaq3bMOufTWPJ3wXfDr1jTG2CUQbHHLsTyYwONV2iDD26zDoiamsLo59iKJYAtXstTtj3v+BJJScvG7/wSq2lx2oLWfUGxsx80iIKmjn9u98268TvJaeTBO6b3WGCtXmFCzIDBtT2yOovCJ4KeDa8bODLg8lmt/v16t3MPF7a8bewGq9mjangBe27g5dsnOyiigvTNfxQLF02khXX67cTlW14Sf2aPcXvfA/Fm/ezeCjreeJZtjhtnbj3Q12OjkeDR7JZlI9CnSWybqSU7xemhG8cT/WQVVL91ewZPPusOtcOq62FBeqK3lFQPtPuPjjZPNFLBlQVRKCk1tZwfvfbuTtOfWr5K7829dc7XeBstj+bH1tg16Iz/49KuMV9vtl/09WyWlukqZ7SZQHPtqMlpXB6b5zeyRlvyPeqTtm376D9duxrhr/NWf9eUbU+wz1g98XMCpyuDHu/Buz/TPLuHrrxbBRMoJTqt39zgLufmcBt781n7vfqT8mYyi+0qoX3oPjH/osqfuv+eol4VR3ORBYk0XbnJIrK4NTu+YNk7LftwKurPceqF8VGOs9GoH3OYUS7srWvyYulZnltOXFju8z1fnB23M28Pac2Gcwzg3RoeWpz5YHbesrr6hi/vqSuNLos3PvQdY63KHDJ1xGLCF6liab273lsmX+KrdkZXBq0yR4pwinhWueifaHVRWwXqjNwlV3+ZeqEg1OTv4gt5SWM/H74B1NvOCThfGnzVetNyHI+fk6imzYta/mJtt73lvIBWO/rHlec2NrDG/3oMencKpDXeFDCRZAa2/CdT6zDlcj4HahNPCzqa6O3HNWRS8rg1NRl1ZcNbBzUvY9dkrtDLAP/HcxQ58NPt13tD+swCAWMjhF2ebk30khngtPJy9WBz7yObe8No9lMUxYmJeTuuqyF6atjnvbHF9wsnt5+mfcvs/gR49N4eRHvwDg+40lAOyxR7qvmfE4hgx/z4HYR8mPlu87FGxyydo2p2QcOPRLbpecAo2dspJBT0xl5TZv3Y+VrrIyOAE8dEFPTrV7VDnpiU+X1Tz+cMGmkDPFRtt4PHtN3cbgUJlVuB55/q8lOtVGMrKDWat3RL2ur0RSGcuEVnFKJPPLDfg4/Nv9gt3MHE8w8ora+5yS0AEm4H3c79fW6rWS09drrNstNpWk17BdXpW1wQngletO4Ovfnx7XtksfGsrSh4bGfexof8fvzqvb3hFPtV7IkpMDGWGHFvXb75qGGf09mFhKQfm5vq70yb+HKpHeZ4HVUTl+dbwVQQJrPNV4/t765of4NoxDYEefwLTvd3AKc/93ceW2Mo4d/UnN8/Ik3OQdi3S8kEgnWR2cAA5tVhhxnReH9695/N4tJ/Pi8P4U5udSmJ/LkgcjB6hgpZVYMr7Ji7cyfXlx2BJGuAze/weeaKYezdXxoBhLpLG8F7n23cmpqNaLMFpTWIEl2Vy/59F8BjVjK0Z5niPe/b7m8WeLt7Kn3NnRFPzP5sP5m+q+5jdCxJrtezl29CdBu93Hw//slwbcgrFia/S3cXy9eocjE3T681itYsbJ+uAE8M5NJ9U8PrePNVvu4KPb8vP+HQE487hDGdClJeOu6k+/Ti0Z2vOwmvUbNsjljRsGht3/3iBdyvf4zaIbKcP/5T/ncPX42Vw2bhbzfgh+z8fPX/wq5Pb+GfkHdsYy4OHJjIujTWVlFPd1hRoiKpRYAo0vkw9W+nBa4L1kscjNCf08XJWk76uQb28Qz3ne8M85DHh4csSxEGPhH2sDq9r8Byn2jX83adFWx45de9y6B462GnHa8mIuHTeLv82Mvw0xmFBH99iwiGlLgxNwfKeWNY+fu7wfr99wIs9dcTyPXdSbxQ+eiYjw75tOZshxhwXd/qTurVn76LCQ+/8oyNBH/jdG+h53bBm5i/uuvbFfEQeOivHHjxZTvOcAT322vN66U5ZuC7uvwK7KJfvq3ocyZdm2ej0MIwk3ksQ3a3dS5tfQHzh8UzKFunn1X7PW8c7c8N3LAwe99b8YCQx6R94zsaZt0leKzM/LCbputMorqhn+96+DvvbtD7voMnICK7eVUV1tat7fCd9tptuoCTXVctv2lNf0zvMPDP+atY63v1nP3gN1O2+8MHVVXGkNVF1taqZbCfdVivY74BuGzOlxE700xUqiNpbsD1uynL++hKVbwg8e4DRXg5OIDBWRZSKyUkRGupWOnBxh9Z/OZuXDZwFwcvc2NCnIIzdHaNQg+vaTJy/uE3T5qP98X2/ZmX69+Pr/cTLGmKjq6p+ZXD+gBJqydBvGGKqrDRVV1fwtYOqKwOf+rnvlm7D7nr6i7tQFewPSfN3L3/DqrNr2jy4jJ9Bl5ISo7r8p3V/Br1+fx6RFW/h+QynPfb6Ci1/8itvf/LbeuhUpaHMKFZz+8P5CfvfvBXWWBU4P4t+FfNmWPfx1eu1V+2lPTWP2mtqxCv1LR74gtniTNdPr1GXFzF0X+7iGALNW19+uvKKK97/dCMCMFcU8NGExPe/7lPKKKp6dvJxqA6uKy9hRdoBhY2ZywdgvgbrVegs37ubud7/juPs+BWpLTm/NWV8zYsrkJVtZEOG+rdL9FUFLP3+ZspKBj3zO+p376hRPXvnf2jrrrSwu478LNlG6L/wFmy/TDdctPRYN7FKtb0izHWUHKN1fUTNlzMZd+5m5YjuLN9XNzIv3HKB4T91hxrbtLo+phPt/b3xLl5ETGB/wfTPGRBx5JpQNu/ZxyqNf8OznK0KuM/Ld73h6UuS8x0niVndMEckFlgM/BTYA3wCXG2MWh9qmqKjIzJkzJ0UpjI8xhute+YabBnXnsnH1B5ONxrUnd+HcPu3p37kly7bsqRPIstWlRYdTXHaAVcVlrNtROyBvv04t6Nm+OYc2K+D4zi15etJyjjy0KQs3lrJr30FO7t4aY+DSAYfTolE+zRtaVY6zVu/g8FaNaN24AT9+fIpbpxWzHx3Rhpkrt3Pzqd0dK6kANGqQW2/UEZ9fD+5Oq8YFPPRR/Z9mv04t+DbMbMg+vTs2Z+HGUn49+AhWF+/lkGYFvPzl2nrr/fmyvtz+1vyUtefc+dOjGHz0IXRq3YjJi7cyZdk2Rp/bg7LySnaXVyJAQb4VjA5UVLNk825GBrnYDOUXp3TlnD7t+HD+pprgOmvU6Xy9Zge3vTm/Zr0OLRry9CV9KC47wMHKajq2bMT/Vm3n7zPWsOdAJbk5ErSkeH7f9jQuyOP1r60LwruHHs0nC7fw3YZSOrduVPNbGXXWMVatRrXhiEOaYozh8FaN2Ln3II0a5PLcFyvr7PeELq3YsGsf1QaOadeUqcuKObZdMz6+7ccxvLv1ichcY0xRVOu6GJxOAu43xpxpPx8FYIx5JNQ26RCcAi3fuodLnpnAiTlLWVjdhWpy2E0jGlPO8LzP+KzZRZhd6/io4F4A/tp9LL+6ani9/ew7WEmf0RN4If8Z2shurjYPcGbP9vz7280U5AlNKkvJo4oTc5YwpsHYetuvqm5H9S2zeXryCuYvXMRpud/ycP54AB7s8wUNChszbtoKVhfWP3YwT1f8nN004oLcL+mbs4oF1yylWdNmXPHku4xv8DjvVA3ilaoz6SOr+E/B/fG/gTFYU30oZTSkihz65gRvX9hiaqtwm7KPxhJ8wNxfH/w/xjYYk5R0pqN9poBGId6rdPJ5VT9Oz61fEg+01bRgp2lKY8ppKvvZZZpwkHzyqaR7TmI3jm8wbegoyZk8cbNpRTuJr6QdyRdVfTntoWkJ7SNdgtPPgaHGmF/az68CTjTG/CZgvRuBGwE6derUf906r80MGsSW76HNUfDHQ+Lb/r6Suv1zv/wzTL7PseQlxcm3wv+eS9ru9+a1oHFlScjX90tDdrTozYY91XRgG4dX1v2e7JOGbGtyLBXNulBtDIs37+ao5gbToAk9t32YtHRngh3SihaUkmuS33V7VXW7hDP/WB0kj72NO9Fyr3VBs7TVGTRs3JhG1WXk7N/FwdyGVOcUUIXQaevnMe27GiEnoOvE6g7n0W2j9Z0LFvSX5XRjT25LiirmJnBWzqssbE3eyMQ6laRLcLoYODMgOJ1gjLk11DaeLzntWgd/7u3c/npdAt+/Hd+2V70PbY8ByYGnjop9+6OGwgUvwN5iaNoOHj08vnT4O3wg9LwQOp0EufnwvN3Lse+V0OMCeP3i4Nu17AK32W08a2bAP86xHv9uBTQJcQHg+17vWgOrp0HRdaHTdX/z6M/hqvfgXz+ztyutu+3VH8A/z49uP+c/Dx/cEmT/70PHIpgzHj4bXbt89E7Iya27bnkpPNop/HEC03jHYlj+CUy4Ey57A6Y/Dpu+hd9vgsoD8MVDcMpt1vv37vWwca61j6+eh09H1e7njAfg6LOh7VHwaGcoL4GGraDNkbDe7ojRoQhuCJOZr/sfdOgPeQW1aby/FD5/EGY8BTd9Cc07wGNdgm9/y9ewbTG06gq7N1nf92YdIL8QJj8Aa6bBDV/AFw9b5zloJAweVff9+MldcNq99rH90hDK0onw5uXW49/MhfyG1nes9ZHw9lXWuV/3MWxdBIccC11+VLvtysnW/yPOCL3/QMZA6Xpo0cn6fDbOg5eHQqM2cLdftW5VBXz/DvS+tHYyuFgZY10U79sJBU2t36hPdbX1WoLtdrEEJzfnc9oA+Od4HYFNIdZNvtcvhdKNcPNMKF5mZYh5BbWvHyizvoiBGYS/WALTeX+BD+1C4lXvQffT4NneUOJ3xR9vYAr8cTXvBKUx3qR5zDnQqJX152/YUzDht7XP8wqh0u+O+I4nQPOOsOg/1vPbF0KDxtCgCeSF6GLeuC0cNaQ2I23U2spIti2GuS9Tpzm+0r7K7DY4dGCC2h9Rq27WXzyadYTdAb3yup9mZeqFzeou//0m6zx9+g6H+a9aj+8vhU9Gwaznred3r7HeV19wur8UxvSDnautTKigKRywRxbpNxwG3xv+exfoni3wcPCepTTvAAOuh2PPgyZtoetPYOcq+zNqDOc8U7vuNf+F/SXW4waNapdf+BL0vqT2eYXdBnjrXFg/G9641HqeG+GWgs4n131+wq+s/6f+3krfYT1hv9+tE9dOhFfOrn3eqhsccoz1uH2/uvs6w6+modruMOGf2RY2t7Yv+kXtsl98amXy4bTvW/u4RSfrO928g/Xc2B0bJBdOuKH+trEEJR8R6zhg5UedTwoePHPzoe/lse8/8FhQ/zcP8Qe8BLgZnL4BjhSRrsBG4DLgCldSsvBd62oSrCq0z0bD8ddYV/jzX7N+pI90sDKK8+u352AMPNAitmMee05tcOo22Prv/0MMZcgfYdK9sR2rY1HswalriIbPwwICcKtuVhDx+eVn8NEdtc9bhClxdf4RrJtplcx8Ln8TDutlBbgdq+zg5Mf3Hu0K3ePQMc3a1Q9OAMecXX+Zf2ACqA64t038ftzRBBrf9q26WemIRX5D63tyaM/Q6zSxb5QuaALtgvcyrQlY9fbfqO5zX1pzG9Rm0BDbVbZ/hpub5xcE/PZR0LTuNtEG7Jr02cHp9u+hsEX9C4xO4e9XBKBZ+9rHgefnO/dYLiRUSHGHQxG5PZEDG2Mqgd8AnwJLgLeNMYsS2Wfc3vG7evJVpcz7B7x/E6ydAfNft5Z9+6pVgvJXXhp7YIK6V5W+L/mBCF1Bb51X/2rTJ1zpwD8z6XmRtR+AHiGqoO4vtUqOwTRsWff5rrX115kzPnRa/B0aZF6to8+yAlMoVXbJqVmYdbygOtwVeAyZdrzV7iffCt0Hx7dtJKGCGVD31lSn70YNfC+i3H8n+yb7DnZtUotO9QOTE3pfVrt/lbBESk53As8mcnBjzERgYiL7SMh3b1t11JH4tw08Yq8/ehesmVrb/hArieHq6pqPrB9T6+5WG0AwP38Zxg0K/pp/Q3bzjtZ+7tliVZEt/iD6dATjq9JJRKQrbP/Xc+yvbPMoPjc3VYWZJE+CXBN6/YZOX/qOvzp8afjwKEofsfD/7APfo2irmo4ZBnethsatnUsXUC84nnCDVU2Y62aFVOZI5F1M/0E6/hOkXjhaD7aMvE44wTKoYC76e+gqtmhV+/eysj+2/Ib1q54Abg49DFKd7Z0QKUP2eoYdTlXAe+t/LkE/+1Aj+nrtZxYhPY1bW9Xg/zjXmcPV+Q4k8H1wPDBR/7MR0cDkoERaudI356iqiK2HVixOj7LLd7TBqcmhUe4vTKbhH4TqHDfINsGq2lzj+4oFSWeyAtc9W5zZT73A7x+cvBZwEhTPJGPR7zzycVyTYZ+jx4TNIUVkj4jsDvK3B/B4vUoYSyckb98/uiPyOhB9cAoUctiecLOy+ZWc4j1uzfYx/CCPHJLYsYInIAn79JMfML7hob2sru7R8l1MmFCfE2RsppbovB8ReS04qWQKm1MZY5oaY5oF+WtqjEnfLikHkziVsn/mfWgv6//lb9ZfL+qumQE/yFA3QoYtOVVFt57TcvIjrwN4JrMeEKSa9+aZcMHz0e/j17Ot7vM+vs4DJkLJyfd60jP4VHAw7f7vg9fekkwrAXtM3BWkIvKDMSY9u6UEu/kxGW6cagUT//ulEhWsnQgIm8FXhyg5Of3jKgysKo2Um0TZ5pSqTOCMKKtk/f3y87qlpIYtrD/fuZ02OshGYaeGjGHdKP1+M/wpxu7osRCpG0Sa2t2tQ/UsjZuBc/8M/73N4f3GSYNTUiVSx5P5n0ykmwgD/SpggNbcvPgC02+X1/YiDLyCDhmcwqizTRI/tt8EjN5xMMrJ4CL+yFP0VcuJ41qtYxEcfkLo1wOTnldY92bQiKIpLgj8dlnolwOrKp0W+B1te5Q1esKgEc4fp/+1zu5TeVb2dYiIpbrkl1GMo9VxQO3jsPd/xKDpoaHvW6ooD7482g4Rid6HEqotpX2/+iM2RMrsI34WKf6K5QXMivzj3wZfLy72uZx+n/NX3Dm50PQwazin/4s8qGny+J1XmyOcuRnVqd56Ku2EzT1E5M5QLwFNnE9OChSHuMI8pEfdkQ7AGlbH5/I34Y3L6m/30wfh5bOcS189Dvwg/YdkCdtQH4XqEG1eQXv+HZfYsVItMGgcncDnGnMPtpDzqkY+lu+euSaHAHEONpwOOvR3OwUqhSKVnJqG+GsC/Dm5SUuSyhAljyuCjWNnZxhN21mjjAfjeL16JHaaAscSC9cLL+xoBbEePiA4+Y4bLNONWE2WRVfCvu9Pi87h14unVBXLTcxxc+uzso/bsJUOC5RlwuYexpgHUpWQlPENRRQoWL18pB5WyVTTGSAn+PJ6GX+Y9PW+tHakaP/14jmnwDavk35tT5URLDhFaFvxvR4q00l1h4hkKvqFNWZguPapOmIIBqns2Zfqz8I3nt6PQ1XiqEwVqVovWFcjH2OMecjh9CTf7L+GeCGWHlSpEOoG1BBBK5yiX0DZNpj2aOLJqgwYlidcAIlUchr8e2u7iPcRpWFwCjZ6QLjAFLJWz2vfy2CSGBzzCsJPYaEyVqR6l2A3BDUGrgdaA+kXnGLil/Gm+r6TUCWnGkEyv1BCzsMSQ+bmmz7BN/BqNPuKVA3TsAWc9Vj0aagjyZ9HwyDTBsQi5u9LiIuRdLrfKRNKuMozIlXrPeV7LCJNgduA64A3gadCbZeWwl35J5pRxaNmbpgQmVXMIz0kmHF0/Yn1f2+I6aWDvX+B7WIxC5IxpyIDvO27+tMzxC3e9Hoso/dSkOw4ADZ843YqVJJFvLFDRFphjUB+JfAP4HhjTBQTD3lQrD+wpofBsKetXlsV+0Ovd/E/Yr8nKqJYq/UiZWYOZS6N21jVLG9fA4vfD7/uEacndizfvV4npeimaZ+WETotpISHgoHXXPORM6PhK0+LNLbeE1iTAu4Behlj7k/bwATW3EuhhLoiH3B93QnGwJqIEKCJPdvocRcEn4DOCSFLTjFU64VaL5FSyNlPwIk31Y6fl+iYfcEUNrMCof+Nl166gg8rznT6PhPfrKldohiRPhWlSS9V2eUXBp+tVWWUSCWn3wIHgHuBe6T2CypYHSKSMGNXEm1fHubFGH58g0ZYkxHG84O9dkLi9xpBkGNHmRanMvcmh1jtRWu/jO34jvFQZhlOuO/IhX+rrT4M/Fy6/gRG70yz7tNp8pkkqtPJ8MP/3E5FxovU5pT6ieOT6Ys/Wv/b9YHNC2qX37M1TEN/MGGmcoiky4+iPESoIBKiWi+uNpIMuP8lnfW+OMhC/4kV0ykwZZHh74Rue1WOyazgE0kne5bOa/0m323azqomiCejjqXkNOzp+kMS/WycVX8e/iB1nwZ2iJBca0y/podCr0ugzxURdufw1W2q70XyUvVSNkmb6tQUaNDYI+2SmS27pm3cvdGab6fAb+Ql3/QGsWR68fxQB1xv/fnrc2ns+wksteUV1o7pd9FLYTZL9hw7GjQSky6Zv37OKjWyq+RUsh5aBMzyUTOtcpQ/uvzGfk+S+UONkFnVBNNYMzWHOkT4tO9nDclzerj7tVXUtGSoFJBtJad9O6F5x+CvRZspBI68nWom0ZKKw1foBU3h9u/qLmtyGJQ5NN15KtwyC9bPdnafsZZUL3sNZr1QOxdSTDwS0DSwKgdlV3A6WFa3Sq+OOLpiuyIw03MwPUc71B3+phmwa60z+wrFyWrKQ461/pIiys+nfT+4cFyS0uCEdKl2VJkie4JT5UHYtQbKS6znl/yr7o21MQUdFwfaTLgDgoR47KAmhySxhOn2xUGWc/3iTGWL7AlOvtG099v3EPc4L2CFGO4batjS+n/8VU6kLE6xtjllypWvS+dx6zxoEMsUZpnyfgfQXnsqRbInOPmmxj6kR/DXI10RtugM3U+DU0dZ7Sz3Fsc43XaMImUCTlzBBu6j7TGJ7zNVUn0F37p7ao8Xk1QEjGjeby1VKedkV3C6fjK0DTFpYKRRvnPz4Kr3ap/nOT2WXighqvXyCqz/EaebCLGfQNd9UnfKeZWgLBtSSCmHZU9wAjg8TOYb73BASRd4VeybbDAffr8J8oJMkhjVfgJ0PinWhLnL89VLqUxfKr6rXn+/VabJrvucwvL7gTdqA+c+61pKwiqwhzNscqh1p3pOjB+hpKBDRFKlWZozrXSTaeejPCu7Sk7h+P/o7l7lXjrqCcgMjjoTzh8LPX/uTnKUCkUDl3KQBqcaXvthhahGEYF+w505hGYmyeP5akelvE2r9Xx8GXX3BCfIc5oGkDSXIZ+fBluVYq4EJxG5WEQWiUi1iBS5kYZ6RKx7WS591e2UJIdmLsoRGRJslee5VXJaCFwITHfp+MG17g4NGrmdiiRzeOBXlWX0IkelhittTsaYJQCimaMLNHPJOJ6Zpl1/z8o5nu8QISI3AjcCdOrUKcLaHnHHIthb7HYqlFIqbSUtOInIZOCwIC/dY4z5INr9GGPGAeMAioqK0uOyv3nH0FNzhCW1ozQkrY1Ir25VHLTNUqVY0oKTMeaMZO07Y91fEiQT0GASXJpklhlXdZ1p56O8SruSe03cM9xmiYzL7DOIfjbKQW51Jf+ZiGwATgImiMinbqRDqaTRajClEuJWb733gPcirpjVnL4K1czSHVqaUCoeWq3nWUkKJlr1kmLJvChw4bPU749KEQ1OXqd5gVIqC2lwyhZHn2X9P3KIu+nIOhl2dRG2LS3DzlW5yvM34WYtpxvUO/SH+0ud3adSSiWJlpw8T69G05N2QFEqERqcVHpKl67aKelAkMILGO0QoVJEg5NSyhkauJSDNDgplUzpUsJTymM0OHmWZmpp7YIX4PhroNNJbqfEGRpkVYppbz2vS3ZVyY9/B0edmdxjJIPXq5BadobzxridiiTw+PuuMoYGp2x3+h/cTkF89EoeLV2rTKbVel51yu3W/5ZdXU2GSgNeKUV6JR0qI2jJyat6Xmj9KeUpWlpTqaElJ6WUUp6jwUmpdJfS9jetulOpocFJpSmtXtJAoTKZBieVXrTR3Y8GaJW5NDip9KJdyOtLScDW912llgYnlaa0BOUKLbmqFNHgpJRSynM0OKk0pdVMSmUyDU4qvWi1klJZQYOTUukqlZ1Djhxi/e9zeeqOqbKaBiel0l4KSpOtusL9pdDh+Pqv9b40+cdXWUeDk1IqMec/D6M2uJ0KlWF04FeVXlp0sf637+dqMpSf3DzIbep2KlSG0eCk0kvH/nDLLGhztNspUUolkQYnlX4OOdbtFCilkkzbnJRSSnmOBiellFKeo8FJKaWU57gSnETkCRFZKiLfich7ItLCjXQopZTyJrdKTp8BPY0xvYHlwCiX0qGUUsqDXAlOxphJxphK++ksoKMb6VBKKeVNXmhz+gXwcagXReRGEZkjInOKi4tTmCyllFJuSdp9TiIyGTgsyEv3GGM+sNe5B6gEXgu1H2PMOGAcQFFRkc6ToFQN/TmozJW04GSMOSPc6yJyDXAOcLoxOve2UnHTaURUBnJlhAgRGQqMAAYZY/a5kQallFLe5Vab01+ApsBnIjJfRF50KR1KKaU8yJWSkzHmCDeOq5RSKj14obeeUkopVYcGJ6XSlfYjUhlMg5NSaU9766nMo8FJKaWU52hwUirtafWeyjwanJRKV3rzrcpgGpyUUkp5jgYnpdKV9tZTGUyDk1JpT6v3VObR4KSUUspzNDgppZTyHA1OSimlPEeDk1JKKc/R4KRU2tLeeipzaXBSKt1pZz2VgTQ4KaWU8hwNTkoppTxHg5NSSinP0eCklFLKczQ4KZWuxP75FjR3Nx1KJUGe2wlQSsWpsDkMfRSOGup2SpRynAYnpdLZwJvdToFSSaHVekoppTxHg5NSSinP0eCkVLbIb+R2CpSKmrY5KZUNLvwbdDje7VQoFTUNTkplg94Xu50CpWKi1XpKKaU8R4OTUkopz9HgpJRSynM0OCmllPIcV4KTiDwkIt+JyHwRmSQi7d1Ih1JKKW9yq+T0hDGmtzGmL/ARMNqldCillPIgV4KTMWa339PGgHEjHUoppbzJtfucRORh4GqgFBgcZr0bgRsBOnXqlJrEKaWUcpUYk5xCi4hMBg4L8tI9xpgP/NYbBRQaY+6LYp/FwLoEk9YG2J7gPrwu088x088P9BwzhZ5jXZ2NMW2jWTFpwSlaItIZmGCM6Zmi480xxhSl4lhuyfRzzPTzAz3HTKHnGD+3eusd6ff0PGCpG+lQSinlTW61OT0qIkcD1VjVdDe5lA6llFIe5EpwMsZc5MZxbeNcPHaqZPo5Zvr5gZ5jptBzjJPrbU5KKaVUIB2+SCmllOdocFJKKeU5WROcRGSoiCwTkZUiMtLt9MRCRA4XkSkiskREFonIbfbyViLymYissP+39NtmlH2uy0TkTL/l/UXke/u1MSIibpxTMCKSKyLfishH9vNMO78WIvKOiCy1P8uTMvAc77C/owtF5A0RKUz3cxSR8SKyTUQW+i1z7JxEpEBE3rKXfy0iXVJ6goQ8xyfs7+p3IvKeiLTwey3552iMyfg/IBdYBXQDGgALgB5upyuG9LcDjrcfNwWWAz2Ax4GR9vKRwGP24x72ORYAXe1zz7Vfmw2cBAjwMXCW2+fnd553Aq8DH9nPM+38/gH80n7cAGiRSecIdADWAA3t528D16b7OQI/AY4HFvotc+ycgFuAF+3HlwFveeQchwB59uPHUn2Orn+hU/TGnwR86vd8FDDK7XQlcD4fAD8FlgHt7GXtgGXBzg/41H4P2gFL/ZZfDvzV7fOx09IR+Bw4jdrglEnn1wwr45aA5Zl0jh2A9UArrJ7AH9kZXNqfI9AlION27Jx869iP87BGW5BknUu05xjw2s+A11J5jtlSref70fhssJelHbs43A/4GjjUGLMZwP5/iL1aqPPtYD8OXO4FzwJ3Y9375pNJ59cNKAZetqsu/yYijcmgczTGbASeBH4ANgOlxphJZNA5+nHynGq2McZUYo032jppKY/PL7BKQpCic8yW4BSsvjrt+tCLSBPgXeB2U3dk93qrBllmwix3lYicA2wzxsyNdpMgyzx7frY8rGqTF4wx/YC9WNVBoaTdOdrtLudjVfW0BxqLyPBwmwRZ5ulzjEI85+Tp8xWRe4BK4DXfoiCrOX6O2RKcNgCH+z3vCGxyKS1xEZF8rMD0mjHmP/birSLSzn69HbDNXh7qfDfYjwOXu+0U4DwRWQu8CZwmIq+SOecHVto2GGO+tp+/gxWsMukczwDWGGOKjTEVwH+Ak8msc/Rx8pxqthGRPKA5sDNpKY+BiFwDnANcaew6OVJ0jtkSnL4BjhSRriLSAKtB7kOX0xQ1u8fL34Elxpin/V76ELjGfnwNVluUb/lldg+ZrsCRwGy7+mGPiAy093m13zauMcaMMsZ0NMZ0wfpsvjDGDCdDzg/AGLMFWC/WsF0ApwOLyaBzxKrOGygijey0nQ4sIbPO0cfJc/Lf18+xvv+ul5xEZCgwAjjPGLPP76XUnKNbDYwuNPadjdXLbRXWtB2upymGtP8Iqwj8HTDf/jsbq872c2CF/b+V3zb32Oe6DL+eTkARsNB+7S+40PAa4VxPpbZDREadH9AXmGN/ju8DLTPwHB/AGsh5IfAvrB5daX2OwBtYbWgVWCWA6508J6AQ+DewEqu3WzePnONKrHYiX57zYirPUYcvUkop5TnZUq2nlFIqjWhwUkop5TkanJRSSnmOBiellFKeo8FJKaWU52hwUsphIlIlIvP9/hwbBV9EuviPHK1UpnJlmnalMtx+Y0xftxOhVDrTkpNSKSIia0XkMRGZbf8dYS/vLCKf2/PmfC4inezlh9rz6Cyw/062d5UrIi+JNW/SJBFp6NpJKZUkGpyUcl7DgGq9S/1e222MOQHr7vln7WV/Af5pjOmNNbjmGHv5GGCaMaYP1jh8i+zlRwJjjTHHASXARUk9G6VcoCNEKOUwESkzxjQJsnwtcJoxZrU9kO8WY0xrEdmONTdQhb18szGmjYgUAx2NMQf89tEF+MwYc6T9fASQb4z5YwpOTamU0ZKTUqllQjwOtU4wB/weV6FtxyoDaXBSKrUu9fv/lf34f1ijsQNcCcy0H38O3AwgIrki0ixViVTKbXrFpZTzGorIfL/nnxhjfN3JC0Tka6wLw8vtZf8HjBeRu7Bmy73OXn4bME5ErscqId2MNXK0UhlP25yUShG7zanIGLPd7bQo5XVaraeUUspztOSklFLKc7TkpJRSynM0OCmllPIcDU5KKaU8R4OTUkopz9HgpJRSynP+Hw+Sh1PQ8jQxAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "model = train_bigan(get_dt_string() + \"_model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}