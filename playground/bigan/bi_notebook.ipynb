{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.datasets.ffhq_dataset import FFHQDataset\n",
    "from data.datasources.ffhq_datasource import FFHQDatasource\n",
    "from data.datasources.golden_age_face_datasource import GoldenAgeFaceDatasource\n",
    "from functional.losses.bi_discriminator_loss import BidirectionalDiscriminatorLoss, BidirectionalDiscriminatorLossType\n",
    "from networks.bigan import BiGAN\n",
    "from training.bigan_trainer import BiGANTrainer\n",
    "from utils.config_utils import read_config, Config\n",
    "from utils.logging_utils import *\n",
    "from utils.plot_utils import *\n",
    "\n",
    "from data.datasets import facedataset\n",
    "from data.datasources import facedatasource\n",
    "from data.datasources.datasource_mode import DataSourceMode\n",
    "from networks.siamese_network import SiameseNetwork\n",
    "from functional.losses.contrastive_loss import ContrastiveLoss\n",
    "from functional.metrics.dissimilarity import *\n",
    "from training.face_recognition_trainer import train_epochs\n",
    "from configs.base_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save_best_loss_model(model_name, model, best_loss):\n",
    "    # print('current best loss: ' + str(best_loss))\n",
    "    logging.info('current best loss: ' + str(best_loss))\n",
    "    torch.save(model, base_dir + 'playground/bigan/results/' + model_name + \".pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image: 0\n",
      "reading image: 512\n",
      "reading image: 1024\n",
      "reading image: 1536\n",
      "reading image: 2048\n",
      "reading image: 2560\n",
      "reading image: 3072\n",
      "reading image: 3584\n",
      "reading image: 4096\n",
      "reading image: 4608\n",
      "reading image: 5120\n",
      "reading image: 5632\n",
      "reading image: 6144\n",
      "reading image: 6656\n",
      "reading image: 7168\n",
      "reading image: 7680\n",
      "reading image: 8192\n",
      "reading image: 8704\n",
      "reading image: 9216\n",
      "reading image: 9728\n",
      "reading image: 10240\n",
      "reading image: 10752\n",
      "reading image: 11264\n",
      "reading image: 11776\n",
      "reading image: 12288\n",
      "reading image: 12800\n",
      "reading image: 13312\n",
      "reading image: 13824\n",
      "reading image: 14336\n",
      "reading image: 14848\n",
      "reading image: 15360\n",
      "reading image: 15872\n",
      "reading image: 16384\n",
      "reading image: 16896\n",
      "reading image: 17408\n",
      "reading image: 17920\n",
      "reading image: 18432\n",
      "reading image: 18944\n",
      "reading image: 19456\n",
      "reading image: 19968\n",
      "reading image: 20480\n",
      "reading image: 20992\n",
      "reading image: 21504\n",
      "reading image: 22016\n",
      "reading image: 22528\n",
      "reading image: 23040\n",
      "reading image: 23552\n",
      "reading image: 24064\n",
      "reading image: 24576\n",
      "reading image: 25088\n",
      "reading image: 25600\n",
      "reading image: 26112\n",
      "reading image: 26624\n",
      "reading image: 27136\n",
      "reading image: 27648\n",
      "reading image: 28160\n",
      "reading image: 28672\n",
      "reading image: 29184\n",
      "reading image: 29696\n",
      "reading image: 30208\n",
      "reading image: 30720\n",
      "reading image: 31232\n",
      "reading image: 31744\n",
      "reading image: 32256\n",
      "reading image: 32768\n",
      "reading image: 33280\n",
      "reading image: 33792\n",
      "reading image: 34304\n",
      "reading image: 34816\n",
      "reading image: 35328\n",
      "reading image: 35840\n",
      "reading image: 36352\n",
      "reading image: 36864\n",
      "reading image: 37376\n",
      "reading image: 37888\n",
      "reading image: 38400\n",
      "reading image: 38912\n",
      "reading image: 39424\n",
      "reading image: 39936\n",
      "reading image: 40448\n",
      "reading image: 40960\n",
      "reading image: 41472\n",
      "reading image: 41984\n",
      "reading image: 42496\n",
      "reading image: 43008\n",
      "reading image: 43520\n",
      "reading image: 44032\n",
      "reading image: 44544\n",
      "reading image: 45056\n",
      "reading image: 45568\n",
      "reading image: 46080\n",
      "reading image: 46592\n",
      "reading image: 47104\n",
      "reading image: 47616\n",
      "reading image: 48128\n",
      "reading image: 48640\n",
      "reading image: 49152\n",
      "reading image: 49664\n",
      "reading image: 50176\n",
      "reading image: 50688\n",
      "reading image: 51200\n",
      "reading image: 51712\n",
      "reading image: 52224\n",
      "reading image: 52736\n",
      "reading image: 53248\n",
      "reading image: 53760\n",
      "reading image: 54272\n",
      "reading image: 54784\n",
      "reading image: 55296\n",
      "reading image: 55808\n",
      "reading image: 56320\n",
      "reading image: 56832\n",
      "reading image: 57344\n",
      "reading image: 57856\n",
      "reading image: 58368\n",
      "reading image: 58880\n",
      "reading image: 59392\n",
      "reading image: 59904\n",
      "reading image: 60416\n",
      "reading image: 60928\n",
      "reading image: 61440\n",
      "reading image: 61952\n",
      "reading image: 62464\n",
      "reading image: 62976\n",
      "reading image: 63488\n",
      "reading image: 64000\n",
      "reading image: 64512\n",
      "reading image: 65024\n",
      "reading image: 65536\n",
      "reading image: 66048\n",
      "reading image: 66560\n",
      "reading image: 67072\n",
      "reading image: 67584\n",
      "reading image: 68096\n",
      "reading image: 68608\n",
      "reading image: 69120\n"
     ]
    }
   ],
   "source": [
    "golden_age_config = read_config(Config.GOLDEN_AGE_FACE)\n",
    "datasource = GoldenAgeFaceDatasource(golden_age_config, mode=DataSourceMode.TRAIN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image: 0\n"
     ]
    }
   ],
   "source": [
    "annot_path = golden_age_config.annotations_folder_path\n",
    "additional_data = datasource.get_additional_data(annot_path=annot_path,\n",
    "                               from_image_count=70000,\n",
    "                               additional_image_count=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "datasource.data = np.concatenate((datasource.data, additional_data), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-4bedccf32c22>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_config\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mConfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBiGAN\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrain_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFFHQDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatasource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdatasource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtrain_dataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_config\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'read_config' is not defined"
     ]
    }
   ],
   "source": [
    "train_config = read_config(Config.BiGAN)\n",
    "train_dataset = FFHQDataset(datasource=datasource)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_config.batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_golden_age_face_bigan(model_name='test_model'):\n",
    "    logging.info(\"initiate training\")\n",
    "    net = BiGAN(image_dim=golden_age_config.image_dim).to(ptu.device)\n",
    "    criterion = BidirectionalDiscriminatorLoss(loss_type=BidirectionalDiscriminatorLossType.VANILLA_LOG_MEAN)\n",
    "\n",
    "    d_optimizer = torch.optim.Adam(net.discriminator.parameters(),\n",
    "                                   lr=train_config.discriminator_lr,\n",
    "                                   betas=(train_config.discriminator_beta_1, train_config.discriminator_beta_2),\n",
    "                                   weight_decay=train_config.discriminator_weight_decay)\n",
    "\n",
    "    g_optimizer = torch.optim.Adam(list(net.encoder.parameters()) + list(net.generator.parameters()),\n",
    "                                   lr=train_config.generator_lr,\n",
    "                                   betas=(train_config.generator_beta_1, train_config.generator_beta_2),\n",
    "                                   weight_decay=train_config.generator_weight_decay)\n",
    "    g_scheduler = torch.optim.lr_scheduler.LambdaLR(g_optimizer,\n",
    "                                                    lambda epoch: (\n",
    "                                                                          train_config.train_epochs - epoch) / train_config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    d_scheduler = torch.optim.lr_scheduler.LambdaLR(d_optimizer,\n",
    "                                                    lambda epoch: (\n",
    "                                                                          train_config.train_epochs - epoch) / train_config.train_epochs,\n",
    "                                                    last_epoch=-1)\n",
    "    trainer = BiGANTrainer(model=net,\n",
    "                           criterion=criterion,\n",
    "                           train_loader=train_dataloader,\n",
    "                           test_loader=None,\n",
    "                           epochs=train_config.train_epochs,\n",
    "                           optimizer_generator=g_optimizer,\n",
    "                           optimizer_discriminator=d_optimizer,\n",
    "                           scheduler_gen=g_scheduler,\n",
    "                           scheduler_disc=d_scheduler,\n",
    "                           best_loss_action=lambda m, l: save_best_loss_model(model_name, m, l))\n",
    "    losses = trainer.train_bigan()\n",
    "\n",
    "    logging.info(\"completed training\")\n",
    "    save_training_plot(losses['discriminator_loss'],\n",
    "                       losses['generator_loss'],\n",
    "                       \"Golden Age Face BiGAN Losses\",\n",
    "                       base_dir + 'playground/bigan/' + f'results/bigan_plot.png')\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "# visualize_data()\n",
    "# visualize_golden_age_face_data()\n",
    "# model = train_bigan(get_dt_string() + \"_model\")\n",
    "model = train_golden_age_face_bigan(get_dt_string() + \"_model\")\n",
    "# torch.save(model, base_dir + 'playground/bigan/results/' + \"test_model.pth\")\n",
    "# model = torch.load(\"test_model.pth\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}